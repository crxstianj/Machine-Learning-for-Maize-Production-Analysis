{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-09T17:28:53.452920Z",
     "start_time": "2025-10-09T17:28:52.943950Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from viz import Parcelas\n",
    "\n",
    "parcelas = pd.read_csv(\"parcelas.csv\")\n",
    "nvdi = pd.read_csv(\"parcelas_ndvi.csv\")\n",
    "parcelas['ndvi'] = nvdi['NDVI_promedio']"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T19:56:46.272426Z",
     "start_time": "2025-10-09T19:56:38.965952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "df_copy = parcelas.copy()\n",
    "\n",
    "# Convertir variables no numéricas a numéricas (1,2,3,...)\n",
    "for col in df_copy.columns:\n",
    "    if df_copy[col].dtype == 'object' or str(df_copy[col].dtype) == 'category':\n",
    "        df_copy[col] = df_copy[col].astype('category').cat.codes + 1  # +1 para evitar -1\n",
    "\n",
    "# Separar variables y target\n",
    "X = df_copy.drop(columns=[\n",
    "    '(seco)Masa de rend.(tonne/ha)',\n",
    "    'Flj cultivos(M)(tonne/h)',\n",
    "    'Vol. de rend.(seco)(L/ha)',\n",
    "    'Masa de rend.(húmedo)(tonne/ha)',\n",
    "    '(húmedo)Vol. Rend. (húmedo)(L/ha)',\n",
    "    'Prod.(ha/h)_left',\n",
    "    'Prod.(ha/h)_right',\n",
    "    'Flj cultivos(V)(m³/s)',\n",
    "    'Id obj._right', 'Id obj._left', 'Id', 'index_right',\n",
    "    'geometry', 'Num. de paso_right', 'Num. de paso_left',\n",
    "    'Latitude_right', 'Latitude_left', 'Longitude_right', 'Longitude_left',\n",
    "    'Velocidad del medidor(rpm)', 'Velocidad(km/h)_right', 'Velocidad(km/h)_left',\n",
    "    'Velocidad elev(rpm)', 'Orient veh(deg)_right', 'Orient veh(deg)_left',\n",
    "    'Satélites_right', 'Satélites_left', 'Delvy Spd(rpm)', 'Elevation',\n",
    "    'Elevación(m)_right', 'Elevación(m)_left', 'FD Rueda cal(N)',\n",
    "    # Columnas adicionales de la cosecha\n",
    "    'Lote_left', 'Conjunto de datos_left', 'Producto_left',\n",
    "    'Curso(deg)_left', 'Anch. de fja.(m)_left', 'Distancia(m)_left', 'Duración(s)_left',\n",
    "    'Cuenta de área_left', 'Estado dif._left', 'Tiempo_left', 'Desviación X(m)_left',\n",
    "    'Desviación Y(m)_left', 'Estado dif..1_left', 'Filas activas((1))_left', 'VDOP_left',\n",
    "    'HDOP_left', 'PDOP_left', 'Fecha_left', 'Distancia(m)_right', 'Curso(deg)_right',\n",
    "    'VDOP_right', 'PDOP_right', 'HDOP_right',\n",
    "    'Lote_right', 'Estado dif..1_right', 'Longitude', 'Latitude', 'Desviación X(m)_right',\n",
    "    'Desviación Y(m)_right', 'dist_m', 'Estado dif._right', 'Configuración de DF',\n",
    "    'Estado de apl', 'Tiempo_right', 'Cuenta de área_right', 'FD aplicada(N)',\n",
    "    'Duración(s)_right', 'Anch. de fja.(m)_right', 'Fecha_right',\n",
    "    'Conjunto de datos_right', 'Producto_right', 'Filas activas((1))_right',\n",
    "    'Id. de segmento', 'Pres FD(kPa)'\n",
    "])\n",
    "\n",
    "y = df_copy['(seco)Masa de rend.(tonne/ha)']\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Predicción\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"R² score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Importancia de las features\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features más importantes:\")\n",
    "print(importances.head(50))\n"
   ],
   "id": "f0ffa1901551c9b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 7.17 segundos\n",
      "R² score: 0.8100\n",
      "MAE: 1.4050\n",
      "MSE: 3.5030\n",
      "RMSE: 1.8716\n",
      "\n",
      "Top 10 features más importantes:\n",
      "Humedad(%)                    0.282019\n",
      "Temp. grano(°C)               0.191025\n",
      "ndvi                          0.110232\n",
      "Prop. ap. cta.(ksds/ha)       0.025969\n",
      "Mg                            0.025584\n",
      "OM                            0.023214\n",
      "Leak                          0.021823\n",
      "Mn                            0.021171\n",
      "Countrate                     0.020381\n",
      "K                             0.018696\n",
      "P                             0.016546\n",
      "Loam                          0.015672\n",
      "Vacío(inH2O)                  0.014748\n",
      "Cu                            0.014429\n",
      "Sand                          0.014377\n",
      "PAWater                       0.014145\n",
      "pH                            0.012279\n",
      "B                             0.012247\n",
      "Na                            0.012142\n",
      "Ca                            0.011543\n",
      "Separación adecuada(%)        0.011357\n",
      "Cant. prod.                   0.011325\n",
      "S                             0.011302\n",
      "Zn                            0.010667\n",
      "Fe                            0.009596\n",
      "Clay                          0.009419\n",
      "Ca_Mg                         0.009291\n",
      "Flujo de semilla(ksds/s)      0.008528\n",
      "Silt                          0.008489\n",
      "Cta. semillas((1))            0.006994\n",
      "Espacio entre semillas(cm)    0.005471\n",
      "% densidad(%)                 0.005127\n",
      "Pob. plantas(ksds/ha)         0.005066\n",
      "Singulación(%)                0.003695\n",
      "Dobles(%)                     0.002811\n",
      "Saltos(%)                     0.002158\n",
      "Rate Qual                     0.000297\n",
      "Cal sing                      0.000084\n",
      "parcela                       0.000079\n",
      "Prop. meta(ksds/ha)           0.000000\n",
      "Ca_bse                        0.000000\n",
      "K_Mg                          0.000000\n",
      "K_bse                         0.000000\n",
      "CEC                           0.000000\n",
      "Mg_bse                        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T21:14:21.333376Z",
     "start_time": "2025-10-09T21:14:21.044275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Par = parcelas.drop(columns=[\n",
    "    'Flj cultivos(M)(tonne/h)',\n",
    "    'Vol. de rend.(seco)(L/ha)',\n",
    "    'Masa de rend.(húmedo)(tonne/ha)',\n",
    "    '(húmedo)Vol. Rend. (húmedo)(L/ha)',\n",
    "    'Prod.(ha/h)_left',\n",
    "    'Prod.(ha/h)_right',\n",
    "    'Flj cultivos(V)(m³/s)',\n",
    "    'Id obj._right', 'Id obj._left', 'Id', 'index_right',\n",
    "    'geometry', 'Num. de paso_right', 'Num. de paso_left',\n",
    "    'Latitude_right', 'Latitude_left', 'Longitude_right', 'Longitude_left',\n",
    "    'Velocidad del medidor(rpm)', 'Velocidad(km/h)_right', 'Velocidad(km/h)_left',\n",
    "    'Velocidad elev(rpm)', 'Orient veh(deg)_right', 'Orient veh(deg)_left',\n",
    "    'Satélites_right', 'Satélites_left', 'Delvy Spd(rpm)', 'Elevation',\n",
    "    'Elevación(m)_right', 'Elevación(m)_left', 'FD Rueda cal(N)',\n",
    "    # Columnas adicionales de la cosecha\n",
    "    'Lote_left', 'Conjunto de datos_left', 'Producto_left',\n",
    "    'Curso(deg)_left', 'Anch. de fja.(m)_left', 'Distancia(m)_left', 'Duración(s)_left',\n",
    "    'Cuenta de área_left', 'Estado dif._left', 'Tiempo_left', 'Desviación X(m)_left',\n",
    "    'Desviación Y(m)_left', 'Estado dif..1_left', 'Filas activas((1))_left', 'VDOP_left',\n",
    "    'HDOP_left', 'PDOP_left', 'Fecha_left', 'Distancia(m)_right', 'Curso(deg)_right',\n",
    "    'VDOP_right', 'PDOP_right', 'HDOP_right',\n",
    "    'Lote_right', 'Estado dif..1_right', 'Longitude', 'Latitude', 'Desviación X(m)_right',\n",
    "    'Desviación Y(m)_right', 'dist_m', 'Estado dif._right', 'Configuración de DF',\n",
    "    'Estado de apl', 'Tiempo_right', 'Cuenta de área_right', 'FD aplicada(N)',\n",
    "    'Duración(s)_right', 'Anch. de fja.(m)_right', 'Fecha_right',\n",
    "    'Conjunto de datos_right', 'Producto_right', 'Filas activas((1))_right',\n",
    "    'Id. de segmento', 'Pres FD(kPa)', 'Ca_bse','CEC', 'K_bse', 'K_Mg', 'Mg_bse'\n",
    "])\n",
    "\n",
    "Par.to_csv('Par.csv', index=False)"
   ],
   "id": "d7ff451cc8849862",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T04:46:06.706367Z",
     "start_time": "2025-10-10T04:46:06.223230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index = pd.read_csv('indices.csv')\n",
    "Par = pd.read_csv('Par.csv')\n",
    "Par[['GNDVI', 'NDRE', 'NDMI', 'SAVI']] = index[['GNDVI_promedio', 'NDRE_promedio', 'NDMI_promedio', 'SAVI_promedio']]\n",
    "\n",
    "Par.to_csv('Par.csv', index=False)"
   ],
   "id": "dc890ae53dd1829b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T03:47:38.162881Z",
     "start_time": "2025-10-09T23:37:58.304293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Neuroevolutivo multiobjetivo para regresión (NSGA-II con DEAP + PyTorch).\n",
    "- Optimiza: maximizar R2 y minimizar MSE.\n",
    "- Evoluciona también la selección de features (máscara binaria).\n",
    "- Imprime por época: loss, RMSE y MAE.\n",
    "Ajusta pop_size, ngen y epochs según tu equipo.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# DEAP\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# -----------------------------\n",
    "# Configuraciones del experimento\n",
    "# -----------------------------\n",
    "CSV_PATH = \"Par.csv\"   # <- cambia por la ruta a tu CSV\n",
    "TARGET_COL = \"(seco)Masa de rend.(tonne/ha)\"\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.1   # fracción del train para validación interna\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Parámetros del GA / NSGA-II\n",
    "POP_SIZE = 40      # poblacion (empieza pequeño)\n",
    "NGEN = 50\n",
    "CXPB = 0.6\n",
    "MUTPB = 0.3\n",
    "\n",
    "# Parámetros de entrenamiento (por individuo)\n",
    "EPOCHS = 25\n",
    "EARLY_STOPPING_PATIENCE = 6  # opcional\n",
    "VERBOSE_PER_EPOCH = False     # imprime por época (lo pediste)\n",
    "\n",
    "# Hiperparametros espacio\n",
    "MIN_LAYERS = 1\n",
    "MAX_LAYERS = 5\n",
    "MIN_NEURONS = 8\n",
    "MAX_NEURONS = 512\n",
    "BATCH_CHOICES = [16, 32, 64, 128]\n",
    "ACTIVATIONS = ['relu', 'tanh']\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Carga y preprocesado\n",
    "# -----------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.drop(columns=['parcela'])\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "# Asegurarnos target existe\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"No encontré la columna target '{TARGET_COL}' en {CSV_PATH}\")\n",
    "\n",
    "# Separar X e y (mantener columnas en orden)\n",
    "X_all = df.drop(columns=[TARGET_COL])\n",
    "y_all = df[TARGET_COL].astype(float).values\n",
    "\n",
    "feature_names = list(X_all.columns)\n",
    "N_FEATURES = len(feature_names)\n",
    "print(f\"Features totales: {N_FEATURES}\")\n",
    "\n",
    "# Rellenar NaNs y dividir (puedes mejorar el preprocesado segun tu caso)\n",
    "X_all = X_all.fillna(0).astype(float).values\n",
    "\n",
    "# Split test final, y train+val\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Scaler fit sobre trainval (lo aplicaremos internamente para cada individuo)\n",
    "scaler_global = StandardScaler().fit(X_trainval)\n",
    "\n",
    "# -----------------------------\n",
    "# Model helper (PyTorch MLP)\n",
    "# -----------------------------\n",
    "class MLPRegressorTorch(nn.Module):\n",
    "    def __init__(self, input_dim, n_layers, neurons, activation='relu', dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        act = nn.ReLU if activation == 'relu' else nn.Tanh\n",
    "        in_dim = input_dim\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(in_dim, neurons))\n",
    "            layers.append(act())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            in_dim = neurons\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "# -----------------------------\n",
    "# Fitness: (R2, MSE) (R2 maximiza, MSE minimiza)\n",
    "# -----------------------------\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# --- Gen: máscara binaria para features ---\n",
    "def gen_feature_bit():\n",
    "    return random.choice([0, 1])\n",
    "\n",
    "# --- Gen: hiperparámetros ---\n",
    "def gen_n_layers():\n",
    "    return random.randint(MIN_LAYERS, MAX_LAYERS)\n",
    "\n",
    "def gen_neurons():\n",
    "    # sample log-uniform-ish integer\n",
    "    return int(2 ** random.randint(int(math.log2(MIN_NEURONS)), int(math.log2(MAX_NEURONS))))\n",
    "\n",
    "def gen_lr():\n",
    "    return 10 ** random.uniform(-4, -2)  # [1e-4, 1e-2]\n",
    "\n",
    "def gen_batch():\n",
    "    return random.choice(BATCH_CHOICES)\n",
    "\n",
    "def gen_activation():\n",
    "    return random.choice(range(len(ACTIVATIONS)))  # index\n",
    "\n",
    "def gen_dropout():\n",
    "    return round(random.uniform(0.0, 0.5), 3)\n",
    "\n",
    "# Individual = [feature_mask (N_FEATURES bits) , n_layers, neurons, lr, batch_idx, activation_idx, dropout]\n",
    "def create_individual():\n",
    "    ind = [gen_feature_bit() for _ in range(N_FEATURES)]\n",
    "    ind += [gen_n_layers(), gen_neurons(), gen_lr(), gen_batch(), gen_activation(), gen_dropout()]\n",
    "    return creator.Individual(ind)\n",
    "\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluacion de un individuo\n",
    "# -----------------------------\n",
    "def evaluate_individual(individual, X_trainval, y_trainval, scaler, epochs=EPOCHS, device=DEVICE, verbose=VERBOSE_PER_EPOCH):\n",
    "    # Decodificar máscara y params\n",
    "    mask = np.array(individual[:N_FEATURES], dtype=bool)\n",
    "    if mask.sum() == 0:\n",
    "        # penalizar individuos sin features\n",
    "        return (-1.0, 1e6)\n",
    "\n",
    "    n_layers = int(individual[N_FEATURES + 0])\n",
    "    neurons = int(individual[N_FEATURES + 1])\n",
    "    lr = float(individual[N_FEATURES + 2])\n",
    "    batch = int(individual[N_FEATURES + 3])\n",
    "    activation_idx = int(individual[N_FEATURES + 4])\n",
    "    activation = ACTIVATIONS[activation_idx % len(ACTIVATIONS)]\n",
    "    dropout = float(individual[N_FEATURES + 5])\n",
    "\n",
    "    # Preparar datos: seleccionar features y escalar\n",
    "    X_sel = X_trainval[:, mask]\n",
    "    scaler_local = StandardScaler().fit(X_sel)  # scaler por conjunto de features seleccionadas\n",
    "    X_scaled = scaler_local.transform(X_sel)\n",
    "\n",
    "    # Split train/val interno\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_scaled, y_trainval, test_size=VALID_SIZE, random_state=RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    # Convertir a tensores\n",
    "    X_tr_t = torch.tensor(X_tr, dtype=torch.float32, device=device)\n",
    "    y_tr_t = torch.tensor(y_tr, dtype=torch.float32, device=device)\n",
    "    X_val_t = torch.tensor(X_val, dtype=torch.float32, device=device)\n",
    "    y_val_t = torch.tensor(y_val, dtype=torch.float32, device=device)\n",
    "\n",
    "    train_ds = TensorDataset(X_tr_t, y_tr_t)\n",
    "    val_ds = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=max(16, batch//2), shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = MLPRegressorTorch(input_dim=X_sel.shape[1],\n",
    "                             n_layers=n_layers,\n",
    "                             neurons=neurons,\n",
    "                             activation=activation,\n",
    "                             dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_val_mse = float('inf')\n",
    "    best_state = None\n",
    "    patience = 0\n",
    "\n",
    "    # Entrenamiento (por época) - imprimimos RMSE y MAE por época si verbose=True\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        preds_val = []\n",
    "        yval_list = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                p = model(xb)\n",
    "                preds_val.append(p.cpu().numpy())\n",
    "                yval_list.append(yb.cpu().numpy())\n",
    "        preds_val = np.concatenate(preds_val)\n",
    "        yval_list = np.concatenate(yval_list)\n",
    "\n",
    "        val_mse = mean_squared_error(yval_list, preds_val)\n",
    "        val_rmse = math.sqrt(val_mse)\n",
    "        val_mae = mean_absolute_error(yval_list, preds_val)\n",
    "        # Imprime por época\n",
    "        if verbose:\n",
    "            print(f\"[Ind feat={mask.sum():03d} | layers={n_layers} neurons={neurons} lr={lr:.4g} batch={batch} act={activation} dropout={dropout}] \"\n",
    "                  f\"Epoch {epoch}/{epochs} - train_loss={train_loss:.6f} val_mse={val_mse:.6f} val_rmse={val_rmse:.6f} val_mae={val_mae:.6f}\")\n",
    "\n",
    "        # Early stopping simple\n",
    "        if val_mse < best_val_mse - 1e-8:\n",
    "            best_val_mse = val_mse\n",
    "            best_state = model.state_dict()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= EARLY_STOPPING_PATIENCE:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping en epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Restaurar mejor estado\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # Calcular métricas finales en validación (usadas para fitness)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_val = model(X_val_t).cpu().numpy()\n",
    "    final_mse = mean_squared_error(y_val, preds_val)\n",
    "    final_r2 = r2_score(y_val, preds_val)\n",
    "\n",
    "    # Devuelve (R2, MSE) como fitness (R2 se maximiza, MSE se minimiza)\n",
    "    return (float(final_r2), float(final_mse))\n",
    "\n",
    "# Registrar función de evaluación (wrapper)\n",
    "toolbox.register(\"evaluate\", partial(evaluate_individual, X_trainval=X_trainval, y_trainval=y_trainval, scaler=scaler_global))\n",
    "\n",
    "# Operadores: crossover y mutación adaptados a nuestro encoding\n",
    "def cx_two_point_masked(ind1, ind2):\n",
    "    # crossover para todo el vector (incluye máscara y hp)\n",
    "    tools.cxTwoPoint(ind1, ind2)\n",
    "    return ind1, ind2\n",
    "\n",
    "def mut_individual(individual, indpb=0.05):\n",
    "    # Mutar máscara bits\n",
    "    for i in range(N_FEATURES):\n",
    "        if random.random() < indpb:\n",
    "            individual[i] = 1 - individual[i]\n",
    "    # Mutar hiperparams con pequeñas probabilidades\n",
    "    if random.random() < 0.2:\n",
    "        individual[N_FEATURES + 0] = gen_n_layers()\n",
    "    if random.random() < 0.3:\n",
    "        individual[N_FEATURES + 1] = gen_neurons()\n",
    "    if random.random() < 0.3:\n",
    "        individual[N_FEATURES + 2] = gen_lr()\n",
    "    if random.random() < 0.2:\n",
    "        individual[N_FEATURES + 3] = gen_batch()\n",
    "    if random.random() < 0.2:\n",
    "        individual[N_FEATURES + 4] = gen_activation()\n",
    "    if random.random() < 0.2:\n",
    "        individual[N_FEATURES + 5] = gen_dropout()\n",
    "    return individual,\n",
    "\n",
    "toolbox.register(\"mate\", cx_two_point_masked)\n",
    "toolbox.register(\"mutate\", mut_individual, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# -----------------------------\n",
    "# Bucle evolutivo\n",
    "# -----------------------------\n",
    "def run_evolution(pop_size=POP_SIZE, ngen=NGEN):\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    # Evaluar población inicial\n",
    "    print(\"Evaluando población inicial...\")\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Hall of Fame (opcional)\n",
    "    pareto_fronts = []\n",
    "\n",
    "    for gen in range(1, ngen + 1):\n",
    "        print(f\"\\n=== Generación {gen}/{ngen} ===\")\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # Crossover & Mutación\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Evaluar nuevos individuos (los que perdieron fitness)\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        print(f\"Evaluando {len(invalid_ind)} individuos nuevos...\")\n",
    "        for ind in invalid_ind:\n",
    "            ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "        # Combinamos y seleccionamos con NSGA-II\n",
    "        pop = toolbox.select(pop + offspring, pop_size)\n",
    "\n",
    "        # Guardar frente de Pareto (solo para análisis)\n",
    "        pareto = tools.sortNondominated(pop, k=len(pop), first_front_only=True)[0]\n",
    "        pareto_fronts.append([(ind, ind.fitness.values) for ind in pareto])\n",
    "\n",
    "        # Estadísticas generacionales\n",
    "        fits = [ind.fitness.values for ind in pop]\n",
    "        r2_vals = [fv[0] for fv in fits]\n",
    "        mse_vals = [fv[1] for fv in fits]\n",
    "        print(f\"Gen {gen} stats: R2 (mean)={np.mean(r2_vals):.4f}, MSE (mean)={np.mean(mse_vals):.6f}\")\n",
    "        # imprime el mejor individuo por R2\n",
    "        best_idx = int(np.argmax(r2_vals))\n",
    "        best_ind = pop[best_idx]\n",
    "        print(f\"Mejor R2 en gen {gen}: {best_ind.fitness.values[0]:.4f} (MSE {best_ind.fitness.values[1]:.6f}) - features seleccionadas: {sum(best_ind[:N_FEATURES])}\")\n",
    "\n",
    "    return pop, pareto_fronts\n",
    "\n",
    "# -----------------------------\n",
    "# Ejecutar\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    final_pop, paretos = run_evolution()\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\nEvolución completada en {elapsed/60:.2f} minutos\")\n",
    "\n",
    "    # Mostrar frente de Pareto final (primer frente)\n",
    "    pareto = tools.sortNondominated(final_pop, k=len(final_pop), first_front_only=True)[0]\n",
    "    print(\"\\nFrente Pareto (R2, MSE) soluciones:\")\n",
    "    for ind in pareto:\n",
    "        print(ind.fitness.values, \"features:\", int(sum(ind[:N_FEATURES])))\n",
    "\n",
    "    # Guardar mejor individuo (ejemplo) - puedes expandir\n",
    "    best_overall = max(final_pop, key=lambda ind: ind.fitness.values[0])\n",
    "    print(\"\\nMejor individuo por R2:\")\n",
    "    print(\"R2, MSE:\", best_overall.fitness.values)\n",
    "    print(\"Num features:\", int(sum(best_overall[:N_FEATURES])))\n",
    "    selected_features = [f for f, bit in zip(feature_names, best_overall[:N_FEATURES]) if bit == 1]\n",
    "    print(\"Features seleccionadas:\", selected_features)\n"
   ],
   "id": "6440f10d3e25f290",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features totales: 43\n",
      "Evaluando población inicial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generación 1/50 ===\n",
      "Evaluando 32 individuos nuevos...\n",
      "Gen 1 stats: R2 (mean)=0.5957, MSE (mean)=7.150304\n",
      "Mejor R2 en gen 1: 0.6570 (MSE 6.066976) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 2/50 ===\n",
      "Evaluando 31 individuos nuevos...\n",
      "Gen 2 stats: R2 (mean)=0.6246, MSE (mean)=6.638557\n",
      "Mejor R2 en gen 2: 0.6748 (MSE 5.751484) - features seleccionadas: 25\n",
      "\n",
      "=== Generación 3/50 ===\n",
      "Evaluando 33 individuos nuevos...\n",
      "Gen 3 stats: R2 (mean)=0.6393, MSE (mean)=6.379831\n",
      "Mejor R2 en gen 3: 0.6748 (MSE 5.751484) - features seleccionadas: 25\n",
      "\n",
      "=== Generación 4/50 ===\n",
      "Evaluando 35 individuos nuevos...\n",
      "Gen 4 stats: R2 (mean)=0.6582, MSE (mean)=6.044628\n",
      "Mejor R2 en gen 4: 0.6922 (MSE 5.443499) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 5/50 ===\n",
      "Evaluando 23 individuos nuevos...\n",
      "Gen 5 stats: R2 (mean)=0.6729, MSE (mean)=5.785041\n",
      "Mejor R2 en gen 5: 0.7323 (MSE 4.733914) - features seleccionadas: 28\n",
      "\n",
      "=== Generación 6/50 ===\n",
      "Evaluando 31 individuos nuevos...\n",
      "Gen 6 stats: R2 (mean)=0.6834, MSE (mean)=5.599810\n",
      "Mejor R2 en gen 6: 0.7323 (MSE 4.733914) - features seleccionadas: 28\n",
      "\n",
      "=== Generación 7/50 ===\n",
      "Evaluando 25 individuos nuevos...\n",
      "Gen 7 stats: R2 (mean)=0.6924, MSE (mean)=5.439380\n",
      "Mejor R2 en gen 7: 0.7323 (MSE 4.733914) - features seleccionadas: 28\n",
      "\n",
      "=== Generación 8/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 8 stats: R2 (mean)=0.7080, MSE (mean)=5.163484\n",
      "Mejor R2 en gen 8: 0.7323 (MSE 4.733914) - features seleccionadas: 28\n",
      "\n",
      "=== Generación 9/50 ===\n",
      "Evaluando 22 individuos nuevos...\n",
      "Gen 9 stats: R2 (mean)=0.7199, MSE (mean)=4.953843\n",
      "Mejor R2 en gen 9: 0.7325 (MSE 4.730180) - features seleccionadas: 29\n",
      "\n",
      "=== Generación 10/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 10 stats: R2 (mean)=0.7262, MSE (mean)=4.843203\n",
      "Mejor R2 en gen 10: 0.7470 (MSE 4.474036) - features seleccionadas: 29\n",
      "\n",
      "=== Generación 11/50 ===\n",
      "Evaluando 26 individuos nuevos...\n",
      "Gen 11 stats: R2 (mean)=0.7317, MSE (mean)=4.745711\n",
      "Mejor R2 en gen 11: 0.7470 (MSE 4.474036) - features seleccionadas: 29\n",
      "\n",
      "=== Generación 12/50 ===\n",
      "Evaluando 33 individuos nuevos...\n",
      "Gen 12 stats: R2 (mean)=0.7351, MSE (mean)=4.684492\n",
      "Mejor R2 en gen 12: 0.7470 (MSE 4.474036) - features seleccionadas: 29\n",
      "\n",
      "=== Generación 13/50 ===\n",
      "Evaluando 28 individuos nuevos...\n",
      "Gen 13 stats: R2 (mean)=0.7379, MSE (mean)=4.635207\n",
      "Mejor R2 en gen 13: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 14/50 ===\n",
      "Evaluando 32 individuos nuevos...\n",
      "Gen 14 stats: R2 (mean)=0.7404, MSE (mean)=4.590669\n",
      "Mejor R2 en gen 14: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 15/50 ===\n",
      "Evaluando 34 individuos nuevos...\n",
      "Gen 15 stats: R2 (mean)=0.7413, MSE (mean)=4.575317\n",
      "Mejor R2 en gen 15: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 16/50 ===\n",
      "Evaluando 30 individuos nuevos...\n",
      "Gen 16 stats: R2 (mean)=0.7436, MSE (mean)=4.534009\n",
      "Mejor R2 en gen 16: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 17/50 ===\n",
      "Evaluando 33 individuos nuevos...\n",
      "Gen 17 stats: R2 (mean)=0.7449, MSE (mean)=4.511033\n",
      "Mejor R2 en gen 17: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 18/50 ===\n",
      "Evaluando 28 individuos nuevos...\n",
      "Gen 18 stats: R2 (mean)=0.7469, MSE (mean)=4.477102\n",
      "Mejor R2 en gen 18: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 19/50 ===\n",
      "Evaluando 32 individuos nuevos...\n",
      "Gen 19 stats: R2 (mean)=0.7491, MSE (mean)=4.437995\n",
      "Mejor R2 en gen 19: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 20/50 ===\n",
      "Evaluando 32 individuos nuevos...\n",
      "Gen 20 stats: R2 (mean)=0.7507, MSE (mean)=4.409910\n",
      "Mejor R2 en gen 20: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 21/50 ===\n",
      "Evaluando 36 individuos nuevos...\n",
      "Gen 21 stats: R2 (mean)=0.7512, MSE (mean)=4.401146\n",
      "Mejor R2 en gen 21: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 22/50 ===\n",
      "Evaluando 27 individuos nuevos...\n",
      "Gen 22 stats: R2 (mean)=0.7530, MSE (mean)=4.367928\n",
      "Mejor R2 en gen 22: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 23/50 ===\n",
      "Evaluando 25 individuos nuevos...\n",
      "Gen 23 stats: R2 (mean)=0.7536, MSE (mean)=4.357189\n",
      "Mejor R2 en gen 23: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 24/50 ===\n",
      "Evaluando 26 individuos nuevos...\n",
      "Gen 24 stats: R2 (mean)=0.7536, MSE (mean)=4.357189\n",
      "Mejor R2 en gen 24: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 25/50 ===\n",
      "Evaluando 34 individuos nuevos...\n",
      "Gen 25 stats: R2 (mean)=0.7536, MSE (mean)=4.357189\n",
      "Mejor R2 en gen 25: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 26/50 ===\n",
      "Evaluando 30 individuos nuevos...\n",
      "Gen 26 stats: R2 (mean)=0.7536, MSE (mean)=4.357189\n",
      "Mejor R2 en gen 26: 0.7536 (MSE 4.357189) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 27/50 ===\n",
      "Evaluando 25 individuos nuevos...\n",
      "Gen 27 stats: R2 (mean)=0.7537, MSE (mean)=4.355896\n",
      "Mejor R2 en gen 27: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 28/50 ===\n",
      "Evaluando 24 individuos nuevos...\n",
      "Gen 28 stats: R2 (mean)=0.7538, MSE (mean)=4.354550\n",
      "Mejor R2 en gen 28: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 29/50 ===\n",
      "Evaluando 19 individuos nuevos...\n",
      "Gen 29 stats: R2 (mean)=0.7539, MSE (mean)=4.353256\n",
      "Mejor R2 en gen 29: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 30/50 ===\n",
      "Evaluando 32 individuos nuevos...\n",
      "Gen 30 stats: R2 (mean)=0.7539, MSE (mean)=4.351963\n",
      "Mejor R2 en gen 30: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 31/50 ===\n",
      "Evaluando 31 individuos nuevos...\n",
      "Gen 31 stats: R2 (mean)=0.7540, MSE (mean)=4.350670\n",
      "Mejor R2 en gen 31: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 32/50 ===\n",
      "Evaluando 31 individuos nuevos...\n",
      "Gen 32 stats: R2 (mean)=0.7541, MSE (mean)=4.349376\n",
      "Mejor R2 en gen 32: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 33/50 ===\n",
      "Evaluando 28 individuos nuevos...\n",
      "Gen 33 stats: R2 (mean)=0.7544, MSE (mean)=4.344203\n",
      "Mejor R2 en gen 33: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 34/50 ===\n",
      "Evaluando 35 individuos nuevos...\n",
      "Gen 34 stats: R2 (mean)=0.7545, MSE (mean)=4.341617\n",
      "Mejor R2 en gen 34: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 35/50 ===\n",
      "Evaluando 34 individuos nuevos...\n",
      "Gen 35 stats: R2 (mean)=0.7546, MSE (mean)=4.340270\n",
      "Mejor R2 en gen 35: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 36/50 ===\n",
      "Evaluando 27 individuos nuevos...\n",
      "Gen 36 stats: R2 (mean)=0.7550, MSE (mean)=4.333751\n",
      "Mejor R2 en gen 36: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 37/50 ===\n",
      "Evaluando 21 individuos nuevos...\n",
      "Gen 37 stats: R2 (mean)=0.7561, MSE (mean)=4.314298\n",
      "Mejor R2 en gen 37: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 38/50 ===\n",
      "Evaluando 30 individuos nuevos...\n",
      "Gen 38 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 38: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 39/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 39 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 39: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 40/50 ===\n",
      "Evaluando 23 individuos nuevos...\n",
      "Gen 40 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 40: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 41/50 ===\n",
      "Evaluando 28 individuos nuevos...\n",
      "Gen 41 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 41: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 42/50 ===\n",
      "Evaluando 27 individuos nuevos...\n",
      "Gen 42 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 42: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 43/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 43 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 43: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 44/50 ===\n",
      "Evaluando 25 individuos nuevos...\n",
      "Gen 44 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 44: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 45/50 ===\n",
      "Evaluando 30 individuos nuevos...\n",
      "Gen 45 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 45: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 46/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 46 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 46: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 47/50 ===\n",
      "Evaluando 30 individuos nuevos...\n",
      "Gen 47 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 47: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 48/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 48 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 48: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 49/50 ===\n",
      "Evaluando 29 individuos nuevos...\n",
      "Gen 49 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 49: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "=== Generación 50/50 ===\n",
      "Evaluando 31 individuos nuevos...\n",
      "Gen 50 stats: R2 (mean)=0.7566, MSE (mean)=4.305456\n",
      "Mejor R2 en gen 50: 0.7566 (MSE 4.305456) - features seleccionadas: 27\n",
      "\n",
      "Evolución completada en 249.66 minutos\n",
      "\n",
      "Frente Pareto (R2, MSE) soluciones:\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "(0.7565625174047217, 4.3054563211808325) features: 27\n",
      "\n",
      "Mejor individuo por R2:\n",
      "R2, MSE: (0.7565625174047217, 4.3054563211808325)\n",
      "Num features: 27\n",
      "Features seleccionadas: ['Flujo de semilla(ksds/s)', 'Cta. semillas((1))', 'Dobles(%)', 'Prop. meta(ksds/ha)', 'Cant. prod.', 'Humedad(%)', 'Temp. grano(°C)', 'Countrate', 'B', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Leak', 'Loam', 'Mg', 'Na', 'OM', 'PAWater', 'pH', 'Sand', 'Silt', 'Zn', 'ndvi', 'Cal sing_Bueno', 'Cal sing_Salto']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T04:52:54.468353Z",
     "start_time": "2025-10-10T04:52:50.108805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('Par.csv')\n",
    "df = df.drop(columns=['parcela'])\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "# Separar variables y target\n",
    "X = df[['Flujo de semilla(ksds/s)', 'Cta. semillas((1))', 'Dobles(%)', 'Prop. meta(ksds/ha)', 'Cant. prod.', 'Humedad(%)', 'Temp. grano(°C)', 'Countrate', 'B', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Leak', 'Loam', 'Mg', 'Na', 'OM', 'PAWater', 'pH', 'Sand', 'Silt', 'Zn', 'ndvi', 'Cal sing_Bueno', 'Cal sing_Salto', 'GNDVI', 'NDMI', 'NDRE', 'SAVI']]\n",
    "\n",
    "y = df['(seco)Masa de rend.(tonne/ha)']\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Predicción\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"R² score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Importancia de las features\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features más importantes:\")\n",
    "print(importances.head(50))\n"
   ],
   "id": "c82337663293f664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 4.20 segundos\n",
      "R² score: 0.8340\n",
      "MAE: 1.2553\n",
      "MSE: 3.0594\n",
      "RMSE: 1.7491\n",
      "\n",
      "Top 10 features más importantes:\n",
      "Humedad(%)                  0.286706\n",
      "Temp. grano(°C)             0.157019\n",
      "GNDVI                       0.088218\n",
      "NDMI                        0.071379\n",
      "Countrate                   0.040294\n",
      "NDRE                        0.035650\n",
      "ndvi                        0.028575\n",
      "SAVI                        0.027491\n",
      "Leak                        0.025480\n",
      "Mg                          0.022837\n",
      "Zn                          0.022070\n",
      "K                           0.021146\n",
      "Cu                          0.016755\n",
      "pH                          0.016680\n",
      "OM                          0.014841\n",
      "Cant. prod.                 0.014723\n",
      "Na                          0.014523\n",
      "PAWater                     0.014092\n",
      "Fe                          0.011040\n",
      "B                           0.010371\n",
      "Cta. semillas((1))          0.009766\n",
      "Ca_Mg                       0.008964\n",
      "Flujo de semilla(ksds/s)    0.008347\n",
      "Sand                        0.007728\n",
      "Loam                        0.007218\n",
      "Clay                        0.006537\n",
      "Silt                        0.005651\n",
      "Dobles(%)                   0.005264\n",
      "Cal sing_Salto              0.000352\n",
      "Cal sing_Bueno              0.000284\n",
      "Prop. meta(ksds/ha)         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:29:18.785401Z",
     "start_time": "2025-10-11T19:49:11.351209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ===============================\n",
    "# CARGA Y PREPROCESAMIENTO\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "df = df.drop(columns=['parcela'])\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# Variables y target\n",
    "X = df.drop(columns=['(seco)Masa de rend.(tonne/ha)'])\n",
    "y = df['(seco)Masa de rend.(tonne/ha)']\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===============================\n",
    "# FUNCIONES DEL ALGORITMO GENÉTICO\n",
    "# ===============================\n",
    "\n",
    "def evaluar_individuo(mask):\n",
    "    \"\"\"Evalúa un individuo usando MSE (negativo porque queremos minimizar).\"\"\"\n",
    "    if sum(mask) == 0:\n",
    "        return -np.inf  # penalizar si no selecciona ninguna característica\n",
    "\n",
    "    cols_sel = X_train.columns[mask == 1]\n",
    "    X_train_sel = X_train[cols_sel].copy()\n",
    "    X_test_sel = X_test[cols_sel].copy()\n",
    "\n",
    "    # Estandarización\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sel = scaler.fit_transform(X_train_sel)\n",
    "    X_test_sel = scaler.transform(X_test_sel)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    y_pred = model.predict(X_test_sel)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    fitness = -mse  # menor MSE -> mayor fitness\n",
    "    return fitness\n",
    "\n",
    "def generar_individuo(n_features):\n",
    "    return np.random.randint(0, 2, n_features, dtype=int)\n",
    "\n",
    "def mutar(mask, p=0.05):\n",
    "    for i in range(len(mask)):\n",
    "        if random.random() < p:\n",
    "            mask[i] = 1 - mask[i]\n",
    "    return mask\n",
    "\n",
    "def cruzar(p1, p2):\n",
    "    punto = random.randint(1, len(p1) - 2)\n",
    "    hijo1 = np.concatenate((p1[:punto], p2[punto:]))\n",
    "    hijo2 = np.concatenate((p2[:punto], p1[punto:]))\n",
    "    return hijo1, hijo2\n",
    "\n",
    "# ===============================\n",
    "# PARÁMETROS EVOLUTIVOS\n",
    "# ===============================\n",
    "N_FEATURES = X_train.shape[1]\n",
    "POBLACION = 20\n",
    "GENERACIONES = 30\n",
    "MUTACION = 0.05\n",
    "ELITE = 2\n",
    "\n",
    "# ===============================\n",
    "# EVOLUCIÓN\n",
    "# ===============================\n",
    "poblacion = np.array([generar_individuo(N_FEATURES) for _ in range(POBLACION)])\n",
    "mejor_fitness = -np.inf\n",
    "mejor_individuo = None\n",
    "\n",
    "for gen in range(GENERACIONES):\n",
    "    fitnesses = np.array([evaluar_individuo(ind) for ind in poblacion])\n",
    "\n",
    "    # Guardar mejor individuo\n",
    "    if fitnesses.max() > mejor_fitness:\n",
    "        mejor_fitness = fitnesses.max()\n",
    "        mejor_individuo = poblacion[fitnesses.argmax()].copy()\n",
    "\n",
    "    print(f\"Generación {gen+1}/{GENERACIONES} | Mejor fitness (neg MSE): {mejor_fitness:.4f}\")\n",
    "\n",
    "    # Selección y nueva población\n",
    "    nueva_poblacion = []\n",
    "    for _ in range(ELITE):\n",
    "        nueva_poblacion.append(mejor_individuo.copy())\n",
    "    while len(nueva_poblacion) < POBLACION:\n",
    "        padres = random.sample(range(POBLACION), 2)\n",
    "        hijo1, hijo2 = cruzar(poblacion[padres[0]], poblacion[padres[1]])\n",
    "        hijo1 = mutar(hijo1, MUTACION)\n",
    "        hijo2 = mutar(hijo2, MUTACION)\n",
    "        nueva_poblacion.extend([hijo1, hijo2])\n",
    "    poblacion = np.array(nueva_poblacion[:POBLACION])\n",
    "\n",
    "# ===============================\n",
    "# RESULTADOS FINALES\n",
    "# ===============================\n",
    "print(\"\\n=== RESULTADOS ===\")\n",
    "print(f\"Mejor fitness (neg MSE): {mejor_fitness:.4f}\")\n",
    "\n",
    "mask_final = mejor_individuo == 1\n",
    "mejores_cols = X_train.columns[mask_final]\n",
    "print(f\"Características seleccionadas ({len(mejores_cols)}):\")\n",
    "print(list(mejores_cols))\n",
    "\n",
    "# Evaluar métricas finales\n",
    "scaler_final = StandardScaler()\n",
    "X_train_sel = scaler_final.fit_transform(X_train[mejores_cols])\n",
    "X_test_sel = scaler_final.transform(X_test[mejores_cols])\n",
    "\n",
    "rf_final = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_final.fit(X_train_sel, y_train)\n",
    "y_pred = rf_final.predict(X_test_sel)\n",
    "\n",
    "print(\"\\nMétricas finales con las características seleccionadas:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n"
   ],
   "id": "3ba51360b361c391",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 1/30 | Mejor fitness (neg MSE): -3.1707\n",
      "Generación 2/30 | Mejor fitness (neg MSE): -3.1707\n",
      "Generación 3/30 | Mejor fitness (neg MSE): -3.1707\n",
      "Generación 4/30 | Mejor fitness (neg MSE): -3.1411\n",
      "Generación 5/30 | Mejor fitness (neg MSE): -3.1411\n",
      "Generación 6/30 | Mejor fitness (neg MSE): -3.1411\n",
      "Generación 7/30 | Mejor fitness (neg MSE): -3.1324\n",
      "Generación 8/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 9/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 10/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 11/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 12/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 13/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 14/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 15/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 16/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 17/30 | Mejor fitness (neg MSE): -3.0472\n",
      "Generación 18/30 | Mejor fitness (neg MSE): -3.0122\n",
      "Generación 19/30 | Mejor fitness (neg MSE): -3.0117\n",
      "Generación 20/30 | Mejor fitness (neg MSE): -3.0117\n",
      "Generación 21/30 | Mejor fitness (neg MSE): -2.9938\n",
      "Generación 22/30 | Mejor fitness (neg MSE): -2.9938\n",
      "Generación 23/30 | Mejor fitness (neg MSE): -2.9938\n",
      "Generación 24/30 | Mejor fitness (neg MSE): -2.9798\n",
      "Generación 25/30 | Mejor fitness (neg MSE): -2.9798\n",
      "Generación 26/30 | Mejor fitness (neg MSE): -2.9798\n",
      "Generación 27/30 | Mejor fitness (neg MSE): -2.9798\n",
      "Generación 28/30 | Mejor fitness (neg MSE): -2.9691\n",
      "Generación 29/30 | Mejor fitness (neg MSE): -2.9691\n",
      "Generación 30/30 | Mejor fitness (neg MSE): -2.8779\n",
      "\n",
      "=== RESULTADOS ===\n",
      "Mejor fitness (neg MSE): -2.8779\n",
      "Características seleccionadas (20):\n",
      "['Dobles(%)', 'Prop. meta(ksds/ha)', 'Humedad(%)', 'Temp. grano(°C)', 'Ca', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Mg', 'OM', 'P', 'Zn', 'ndvi', 'GNDVI', 'NDRE', 'SAVI', 'Cal sing_Doble', 'Cal sing_Salto']\n",
      "\n",
      "Métricas finales con las características seleccionadas:\n",
      "MSE: 2.8779001739909242\n",
      "RMSE: 1.6964374948670888\n",
      "MAE: 1.191594722222222\n",
      "R²: 0.8438877754703555\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T00:16:25.451475Z",
     "start_time": "2025-10-11T23:15:42.750568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# ===============================\n",
    "# CARGA DE DATOS\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "df = df.drop(columns=['parcela'])\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# Variables y target\n",
    "X = df[['Dobles(%)', 'Prop. meta(ksds/ha)', 'Humedad(%)', 'Temp. grano(°C)', 'Ca', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Mg', 'OM', 'P', 'Zn', 'ndvi', 'GNDVI', 'NDRE', 'SAVI', 'Cal sing_Doble', 'Cal sing_Salto']]\n",
    "y = df['(seco)Masa de rend.(tonne/ha)']\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURACION AG\n",
    "# ===============================\n",
    "POP_SIZE = 12\n",
    "GENERATIONS = 18\n",
    "MUTATION_RATE = 0.3\n",
    "TOURNAMENT_SIZE = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ===============================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ===============================\n",
    "def crear_individuo(num_features):\n",
    "    \"\"\"Cada individuo representa: [max_depth, n_estimators, apply_scaling, feature_mask...]\"\"\"\n",
    "    max_depth = random.choice([None] + list(range(3, 20)))\n",
    "    n_estimators = random.randint(50, 300)\n",
    "    apply_scaling = random.choice([0, 1])\n",
    "    feature_mask = [random.choice([0, 1]) for _ in range(num_features)]\n",
    "    # Asegurar al menos una característica seleccionada\n",
    "    if sum(feature_mask) == 0:\n",
    "        feature_mask[random.randint(0, num_features-1)] = 1\n",
    "    return [max_depth, n_estimators, apply_scaling] + feature_mask\n",
    "\n",
    "def fitness(individuo):\n",
    "    max_depth, n_estimators, apply_scaling = individuo[:3]\n",
    "    feature_mask = individuo[3:]\n",
    "\n",
    "    X_selected = X.iloc[:, [i for i, bit in enumerate(feature_mask) if bit==1]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    if apply_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    point = random.randint(1, len(parent1)-1)\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individuo):\n",
    "    idx = random.randint(0, len(individuo)-1)\n",
    "    if idx == 0:  # max_depth\n",
    "        individuo[idx] = random.choice([None] + list(range(3, 20)))\n",
    "    elif idx == 1:  # n_estimators\n",
    "        individuo[idx] = random.randint(50, 300)\n",
    "    elif idx == 2:  # scaling\n",
    "        individuo[idx] = 1 - individuo[idx]\n",
    "    else:  # feature mask\n",
    "        individuo[idx] = 1 - individuo[idx]\n",
    "    return individuo\n",
    "\n",
    "def seleccionar_poblacion(poblacion, fitnesses):\n",
    "    \"\"\"Torneo\"\"\"\n",
    "    selected = []\n",
    "    for _ in range(len(poblacion)):\n",
    "        aspirantes = random.sample(list(zip(poblacion, fitnesses)), TOURNAMENT_SIZE)\n",
    "        winner = min(aspirantes, key=lambda x: x[1])\n",
    "        selected.append(winner[0])\n",
    "    return selected\n",
    "\n",
    "# ===============================\n",
    "# EJECUCION AG CON TRACKING LEGIBLE\n",
    "# ===============================\n",
    "num_features = X.shape[1]\n",
    "feature_names = X.columns.tolist()\n",
    "poblacion = [crear_individuo(num_features) for _ in range(POP_SIZE)]\n",
    "\n",
    "# Lista para guardar el mejor individuo de cada generación\n",
    "mejores_por_generacion = []\n",
    "\n",
    "for gen in range(GENERATIONS):\n",
    "    start_time = time.time()\n",
    "    fitnesses = [fitness(ind) for ind in poblacion]\n",
    "    best_idx = np.argmin(fitnesses)\n",
    "    best_ind = poblacion[best_idx]\n",
    "\n",
    "    print(f\"Generación {gen+1} | MSE mínimo: {fitnesses[best_idx]:.4f}\")\n",
    "    print(f\"Tiempo generación: {time.time() - start_time:.2f} s\\n\")\n",
    "\n",
    "    # Guardar el mejor de esta generación\n",
    "    mejores_por_generacion.append((gen+1, best_ind.copy(), fitnesses[best_idx]))\n",
    "\n",
    "    # Selección\n",
    "    poblacion = seleccionar_poblacion(poblacion, fitnesses)\n",
    "\n",
    "    # Cruce\n",
    "    next_gen = []\n",
    "    for i in range(0, POP_SIZE, 2):\n",
    "        p1, p2 = poblacion[i], poblacion[i+1]\n",
    "        c1, c2 = crossover(p1, p2)\n",
    "        next_gen.extend([c1, c2])\n",
    "\n",
    "    # Mutación\n",
    "    poblacion = [mutate(ind) if random.random() < MUTATION_RATE else ind for ind in next_gen]\n",
    "\n",
    "# Mejor individuo final\n",
    "fitnesses = [fitness(ind) for ind in poblacion]\n",
    "best_idx = np.argmin(fitnesses)\n",
    "best_individuo = poblacion[best_idx]\n",
    "print(\"Mejor individuo final:\", best_individuo)\n",
    "print(\"MSE:\", fitnesses[best_idx])\n",
    "\n",
    "# ===============================\n",
    "# Función para imprimir hiperparámetros legibles\n",
    "# ===============================\n",
    "def print_hyperparams(individuo):\n",
    "    max_depth, n_estimators, apply_scaling = individuo[:3]\n",
    "    feature_mask = individuo[3:]\n",
    "    selected_features = [name for bit, name in zip(feature_mask, feature_names) if bit==1]\n",
    "\n",
    "    print(\"max_depth:\", max_depth)\n",
    "    print(\"n_estimators:\", n_estimators)\n",
    "    print(\"apply_scaling:\", bool(apply_scaling))\n",
    "    print(\"features seleccionadas:\", selected_features)\n",
    "\n",
    "# ===============================\n",
    "# Mostrar generación 21\n",
    "# ===============================\n",
    "gen_21 = mejores_por_generacion[20]  # índice 20 = generación 21\n",
    "print(\"Generación:\", gen_21[0])\n",
    "print(\"MSE:\", gen_21[2])\n",
    "print_hyperparams(gen_21[1])\n",
    "\n"
   ],
   "id": "e195b225ae130d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 1 | MSE mínimo: 2.8002\n",
      "Tiempo generación: 57.53 s\n",
      "\n",
      "Generación 2 | MSE mínimo: 2.9383\n",
      "Tiempo generación: 73.50 s\n",
      "\n",
      "Generación 3 | MSE mínimo: 2.8837\n",
      "Tiempo generación: 104.55 s\n",
      "\n",
      "Generación 4 | MSE mínimo: 2.8258\n",
      "Tiempo generación: 122.19 s\n",
      "\n",
      "Generación 5 | MSE mínimo: 2.8157\n",
      "Tiempo generación: 135.70 s\n",
      "\n",
      "Generación 6 | MSE mínimo: 2.8156\n",
      "Tiempo generación: 147.04 s\n",
      "\n",
      "Generación 7 | MSE mínimo: 2.7890\n",
      "Tiempo generación: 181.80 s\n",
      "\n",
      "Generación 8 | MSE mínimo: 2.8066\n",
      "Tiempo generación: 209.52 s\n",
      "\n",
      "Generación 9 | MSE mínimo: 2.7712\n",
      "Tiempo generación: 190.56 s\n",
      "\n",
      "Generación 10 | MSE mínimo: 2.7571\n",
      "Tiempo generación: 228.34 s\n",
      "\n",
      "Generación 11 | MSE mínimo: 2.7571\n",
      "Tiempo generación: 223.20 s\n",
      "\n",
      "Generación 12 | MSE mínimo: 2.7530\n",
      "Tiempo generación: 286.01 s\n",
      "\n",
      "Generación 13 | MSE mínimo: 2.7530\n",
      "Tiempo generación: 309.72 s\n",
      "\n",
      "Generación 14 | MSE mínimo: 2.7424\n",
      "Tiempo generación: 208.34 s\n",
      "\n",
      "Generación 15 | MSE mínimo: 2.7325\n",
      "Tiempo generación: 283.78 s\n",
      "\n",
      "Generación 16 | MSE mínimo: 2.7325\n",
      "Tiempo generación: 248.36 s\n",
      "\n",
      "Generación 17 | MSE mínimo: 2.7325\n",
      "Tiempo generación: 270.87 s\n",
      "\n",
      "Generación 18 | MSE mínimo: 2.7325\n",
      "Tiempo generación: 190.48 s\n",
      "\n",
      "Mejor individuo final: [None, 284, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
      "MSE: 2.7236674907071614\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 154\u001B[39m\n\u001B[32m    149\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mfeatures seleccionadas:\u001B[39m\u001B[33m\"\u001B[39m, selected_features)\n\u001B[32m    151\u001B[39m \u001B[38;5;66;03m# ===============================\u001B[39;00m\n\u001B[32m    152\u001B[39m \u001B[38;5;66;03m# Mostrar generación 21\u001B[39;00m\n\u001B[32m    153\u001B[39m \u001B[38;5;66;03m# ===============================\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m gen_21 = \u001B[43mmejores_por_generacion\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# índice 20 = generación 21\u001B[39;00m\n\u001B[32m    155\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mGeneración:\u001B[39m\u001B[33m\"\u001B[39m, gen_21[\u001B[32m0\u001B[39m])\n\u001B[32m    156\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMSE:\u001B[39m\u001B[33m\"\u001B[39m, gen_21[\u001B[32m2\u001B[39m])\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T22:50:35.263525Z",
     "start_time": "2025-10-11T22:50:35.196583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('Par.csv')\n",
    "df = df.drop(columns=['parcela'])\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# Columnas de X\n",
    "X_columns = ['Dobles(%)', 'Prop. meta(ksds/ha)', 'Humedad(%)', 'Temp. grano(°C)',\n",
    "             'Ca', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Mg', 'OM', 'P', 'Zn',\n",
    "             'ndvi', 'GNDVI', 'NDRE', 'SAVI', 'Cal sing_Doble', 'Cal sing_Salto']\n",
    "\n",
    "# Lista de ejemplo (tu mejor individuo)\n",
    "individuo = [19, 297, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
    "\n",
    "# Extraer parámetros\n",
    "max_depth = individuo[0]\n",
    "n_estimators = individuo[1]\n",
    "apply_scaling = individuo[2]\n",
    "feature_mask = individuo[3:]\n",
    "\n",
    "print(f\"max_depth: {max_depth}\")\n",
    "print(f\"n_estimators: {n_estimators}\")\n",
    "print(f\"apply_scaling: {'Sí' if apply_scaling else 'No'}\\n\")\n",
    "\n",
    "print(\"Características seleccionadas:\")\n",
    "for col, flag in zip(X_columns, feature_mask):\n",
    "    estado = \"Usada\" if flag == 1 else \"No usada\"\n",
    "    print(f\"- {col}: {estado}\")\n",
    "\n",
    "X_columns = ['Prop. meta(ksds/ha)', 'Humedad(%)', 'Temp. grano(°C)',\n",
    "            'Clay', 'Cu', 'K', 'Mg', 'OM', 'P', 'Zn',\n",
    "            'NDRE', 'Cal sing_Salto']"
   ],
   "id": "9b00b301213d714b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 19\n",
      "n_estimators: 297\n",
      "apply_scaling: Sí\n",
      "\n",
      "Características seleccionadas:\n",
      "- Dobles(%): No usada\n",
      "- Prop. meta(ksds/ha): Usada\n",
      "- Humedad(%): Usada\n",
      "- Temp. grano(°C): Usada\n",
      "- Ca: No usada\n",
      "- Ca_Mg: No usada\n",
      "- Clay: Usada\n",
      "- Cu: Usada\n",
      "- Fe: No usada\n",
      "- K: Usada\n",
      "- Mg: Usada\n",
      "- OM: Usada\n",
      "- P: Usada\n",
      "- Zn: Usada\n",
      "- ndvi: No usada\n",
      "- GNDVI: No usada\n",
      "- NDRE: Usada\n",
      "- SAVI: No usada\n",
      "- Cal sing_Doble: No usada\n",
      "- Cal sing_Salto: Usada\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T01:38:44.965967Z",
     "start_time": "2025-10-12T01:38:39.190490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Modelos base\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "# ===============================\n",
    "# CARGA DE DATOS\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "if 'parcela' in df.columns:\n",
    "    df = df.drop(columns=['parcela'])\n",
    "\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "X = df[['Dobles(%)', 'Prop. meta(ksds/ha)', 'Humedad(%)', 'Temp. grano(°C)', 'Ca', 'Ca_Mg', 'Clay', 'Cu', 'Fe', 'K', 'Mg', 'OM', 'P', 'Zn', 'ndvi', 'GNDVI', 'NDRE', 'SAVI', 'Cal sing_Doble', 'Cal sing_Salto']]\n",
    "y = df['(seco)Masa de rend.(tonne/ha)']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# LISTA DE MODELOS\n",
    "# ===============================\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.01),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.01, l1_ratio=0.5),\n",
    "    \"SVR\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"KNeighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor(max_iter=200, learning_rate=0.1, max_depth=3,\n",
    "                                                          random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreeRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# ENTRENAMIENTO Y EVALUACIÓN\n",
    "# ===============================\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    result = {\n",
    "        \"Modelo\": name,\n",
    "        \"Tiempo(s)\": end_time - start_time,\n",
    "        \"R2_train\": r2_score(y_train, y_train_pred),\n",
    "        \"MAE_train\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"MSE_train\": mean_squared_error(y_train, y_train_pred),\n",
    "        \"RMSE_train\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"R2_test\": r2_score(y_test, y_test_pred),\n",
    "        \"MAE_test\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"MSE_test\": mean_squared_error(y_test, y_test_pred),\n",
    "        \"RMSE_test\": np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Mostrar resultados ordenados por RMSE_test\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(\"RMSE_test\"))\n"
   ],
   "id": "ceb6ca56be4ff387",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.907e+01, tolerance: 6.024e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Modelo  Tiempo(s)  R2_train  MAE_train  MSE_train  \\\n",
      "8   HistGradientBoosting   0.185935  0.770924   1.595406   4.247305   \n",
      "7       GradientBoosting   2.256893  0.787518   1.547252   3.939634   \n",
      "5             KNeighbors   0.001001  0.793905   1.436083   3.821208   \n",
      "4                    SVR   0.350698  0.632870   1.969851   6.806974   \n",
      "6           DecisionTree   0.026260  0.538818   2.273531   8.550780   \n",
      "10            ExtraTrees   0.020700  0.999996   0.000212   0.000073   \n",
      "9               AdaBoost   0.616642  0.521118   2.543997   8.878966   \n",
      "0       LinearRegression   0.012375  0.473265   2.491569   9.766201   \n",
      "1                  Ridge   0.000000  0.472797   2.493637   9.774876   \n",
      "2                  Lasso   0.030577  0.464533   2.520680   9.928103   \n",
      "3             ElasticNet   0.013265  0.458039   2.539450  10.048508   \n",
      "\n",
      "    RMSE_train   R2_test  MAE_test  MSE_test  RMSE_test  \n",
      "8     2.060899  0.692341  1.818435  5.556892   2.357306  \n",
      "7     1.984851  0.689525  1.825747  5.607752   2.368069  \n",
      "5     1.954791  0.679396  1.793581  5.790698   2.406387  \n",
      "4     2.609018  0.615575  1.999412  6.943431   2.635039  \n",
      "6     2.924172  0.511032  2.297160  8.831661   2.971811  \n",
      "10    0.008560  0.508022  1.968667  8.886038   2.980946  \n",
      "9     2.979759  0.493936  2.551781  9.140448   3.023317  \n",
      "0     3.125092  0.468891  2.431380  9.592806   3.097225  \n",
      "1     3.126480  0.468421  2.435297  9.601306   3.098597  \n",
      "2     3.150889  0.461451  2.468429  9.727184   3.118843  \n",
      "3     3.169938  0.455281  2.487805  9.838636   3.136660  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T13:15:48.386308Z",
     "start_time": "2025-10-12T09:02:40.027818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CARGA DE DATOS\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "if 'parcela' in df.columns:\n",
    "    df = df.drop(columns=['parcela'])\n",
    "\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "X = df.drop(columns=['(seco)Masa de rend.(tonne/ha)'])\n",
    "y = df['(seco)Masa de rend.(tonne/ha)']\n",
    "feature_names = X.columns.tolist()\n",
    "NUM_FEATURES = X.shape[1]\n",
    "\n",
    "# ===============================\n",
    "# FUNCIONES DE TRANSFORMACIÓN\n",
    "# ===============================\n",
    "def aplicar_transformaciones(X, transformations):\n",
    "    X_trans = X.copy()\n",
    "    for i, t in enumerate(transformations):\n",
    "        col = X_trans.columns[i]\n",
    "        try:\n",
    "            if t == 1:\n",
    "                X_trans[col] = np.log1p(np.abs(X_trans[col]))           # log(x+1)\n",
    "            elif t == 2:\n",
    "                X_trans[col] = np.sqrt(np.abs(X_trans[col]))            # sqrt(x)\n",
    "            elif t == 3:\n",
    "                X_trans[col] = X_trans[col] ** 2                        # x²\n",
    "            elif t == 4:\n",
    "                X_trans[col] = 1 / (np.abs(X_trans[col]) + 1)           # 1/(x+1)\n",
    "            elif t == 5:\n",
    "                col_data = X_trans[col]\n",
    "                X_trans[col] = (col_data - col_data.mean()) / (col_data.std() + 1e-8)  # z-score individual\n",
    "            elif t == 6:\n",
    "                col_data = X_trans[col]\n",
    "                X_trans[col] = (col_data - col_data.min()) / (col_data.max() - col_data.min() + 1e-8)  # min-max\n",
    "        except Exception:\n",
    "            pass\n",
    "    return X_trans\n",
    "\n",
    "# Diccionario de nombres legibles\n",
    "trans_names = {\n",
    "    0: \"sin cambio\",\n",
    "    1: \"log(x+1)\",\n",
    "    2: \"sqrt(x)\",\n",
    "    3: \"x^2\",\n",
    "    4: \"1/(x+1)\",\n",
    "    5: \"z-score individual\",\n",
    "    6: \"min-max (0–1)\"\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURACIÓN AG\n",
    "# ===============================\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Generación de individuo\n",
    "def gen_individual():\n",
    "    features = [random.randint(0, 1) for _ in range(NUM_FEATURES)]\n",
    "    transformations = [random.randint(0, 6) for _ in range(NUM_FEATURES)]\n",
    "    apply_scaling = [random.randint(0, 1)]\n",
    "    histgb_params = [random.randint(1, 10), random.uniform(0.01, 0.5)]\n",
    "    gb_params = [random.randint(1, 10), random.uniform(0.01, 0.5)]\n",
    "    model_choice = random.randint(0,1)\n",
    "    # 0=HistGB,1=GB\n",
    "    return features + transformations + apply_scaling + histgb_params + gb_params + [model_choice]\n",
    "\n",
    "\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, gen_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# ===============================\n",
    "# FUNCIÓN DE FITNESS\n",
    "# ===============================\n",
    "def eval_model(individual):\n",
    "    # Separar genes\n",
    "    features = individual[:NUM_FEATURES]\n",
    "    transformations = individual[NUM_FEATURES:2*NUM_FEATURES]\n",
    "    apply_scaling = individual[2*NUM_FEATURES]\n",
    "    histgb_depth = max(1, individual[2*NUM_FEATURES + 1])\n",
    "    histgb_lr = max(0.01, individual[2*NUM_FEATURES + 2])\n",
    "    gb_depth = max(1, individual[2*NUM_FEATURES + 3])\n",
    "    gb_lr = max(0.01, individual[2*NUM_FEATURES + 4])\n",
    "    model_choice = int(individual[-1]) % 2  # Esto fuerza a que sea 0 o 1\n",
    "\n",
    "    # Selección de features\n",
    "    selected = [i for i, bit in enumerate(features) if bit == 1]\n",
    "    if len(selected) == 0:\n",
    "        return 1e6,  # penalización\n",
    "\n",
    "    X_sel = X.iloc[:, selected]\n",
    "    trans_sel = [transformations[i] for i in selected]\n",
    "    X_trans = aplicar_transformaciones(X_sel, trans_sel)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Escalado opcional\n",
    "    if apply_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Modelos\n",
    "    models = [\n",
    "        HistGradientBoostingRegressor(max_depth=histgb_depth, learning_rate=histgb_lr, max_iter=200, random_state=42),\n",
    "        GradientBoostingRegressor(max_depth=gb_depth, learning_rate=gb_lr, n_estimators=200, random_state=42),\n",
    "    ]\n",
    "\n",
    "    model = models[model_choice]\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "    except Exception:\n",
    "        mse = 1e6\n",
    "    return mse,\n",
    "\n",
    "toolbox.register(\"evaluate\", eval_model)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# ===============================\n",
    "# EJECUCIÓN AG\n",
    "# ===============================\n",
    "POP_SIZE = 40\n",
    "NGEN = 30\n",
    "CXPB = 0.6\n",
    "MUTPB = 0.4\n",
    "\n",
    "population = toolbox.population(n=POP_SIZE)\n",
    "start_time = time.time()\n",
    "\n",
    "for gen in range(NGEN):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=CXPB, mutpb=MUTPB)\n",
    "    fits = list(map(toolbox.evaluate, offspring))\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    population = toolbox.select(offspring, k=len(population))\n",
    "    best = tools.selBest(population, 1)[0]\n",
    "    best_mse = toolbox.evaluate(best)[0]\n",
    "    # Selección de features y transformaciones\n",
    "    # Lista de características seleccionadas\n",
    "    selected_features_idx = [i for i, bit in enumerate(best[:NUM_FEATURES]) if bit == 1]\n",
    "\n",
    "    # Lista de transformaciones para esas características\n",
    "    selected_transforms = [best[NUM_FEATURES + i] for i in selected_features_idx]\n",
    "\n",
    "    # Crear etiquetas de características -> transformaciones de manera segura\n",
    "    feature_trans_labels = [\n",
    "        f\"{feature_names[i]} -> {trans_names.get(selected_transforms[j], 'Unknown')}\"\n",
    "        for j, i in enumerate(selected_features_idx)\n",
    "    ]\n",
    "    print(f\"\\n=== Generación {gen+1} ===\")\n",
    "    print(f\"MSE del mejor individuo: {best_mse:.4f}\")\n",
    "    print(\"Transformaciones seleccionadas por característica:\")\n",
    "    for label in feature_trans_labels:\n",
    "        print(label)\n",
    "\n",
    "    # =========================\n",
    "    # Hiperparámetros del modelo\n",
    "    # =========================\n",
    "    histgb_depth = max(1, best[2*NUM_FEATURES + 1])\n",
    "    histgb_lr    = max(0.01, best[2*NUM_FEATURES + 2])\n",
    "    gb_depth     = max(1, best[2*NUM_FEATURES + 3])\n",
    "    gb_lr        = max(0.01, best[2*NUM_FEATURES + 4])\n",
    "\n",
    "    print(\"\\nHiperparámetros encontrados:\")\n",
    "    model_choice = int(best[-1]) % 2\n",
    "    if model_choice == 0:\n",
    "        histgb_depth = max(1, best[2*NUM_FEATURES + 1])\n",
    "        histgb_lr = max(0.01, best[2*NUM_FEATURES + 2])\n",
    "        print(\"\\nModelo seleccionado: HistGradientBoostingRegressor\")\n",
    "        print(f\"max_depth: {histgb_depth}, learning_rate: {histgb_lr}\")\n",
    "    else:\n",
    "        gb_depth = max(1, best[2*NUM_FEATURES + 3])\n",
    "        gb_lr = max(0.01, best[2*NUM_FEATURES + 4])\n",
    "        print(\"\\nModelo seleccionado: GradientBoostingRegressor\")\n",
    "        print(f\"max_depth: {gb_depth}, learning_rate: {gb_lr}\")\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTiempo total AG: {end_time - start_time:.2f}s\")\n",
    "\n",
    "# ===============================\n",
    "# RESULTADOS FINALES CON MÉTRICAS\n",
    "# ===============================\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "selected_features_idx = [i for i, bit in enumerate(best_ind[:NUM_FEATURES]) if bit == 1]\n",
    "selected_features = [feature_names[i] for i in selected_features_idx]\n",
    "selected_transforms = [best_ind[NUM_FEATURES + i] for i in selected_features_idx]\n",
    "\n",
    "print(\"\\n=== MEJOR INDIVIDUO ===\")\n",
    "print(\"Modelo:\", ['HistGB','GB'][best_ind[-1]])\n",
    "print(\"Features seleccionadas y transformaciones:\")\n",
    "for i, idx in enumerate(selected_features_idx):\n",
    "    print(f\"  {feature_names[idx]} -> {trans_names[selected_transforms[i]]}\")\n",
    "\n",
    "# Preparar datos\n",
    "X_sel = X.iloc[:, selected_features_idx]\n",
    "X_trans = aplicar_transformaciones(X_sel, selected_transforms)\n",
    "\n",
    "# Escalado si aplica\n",
    "if best_ind[2*NUM_FEATURES]:\n",
    "    scaler = StandardScaler()\n",
    "    X_trans = scaler.fit_transform(X_trans)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir modelo\n",
    "histgb_depth = max(1, best_ind[2*NUM_FEATURES + 1])\n",
    "histgb_lr = max(0.01, best_ind[2*NUM_FEATURES + 2])\n",
    "gb_depth = max(1, best_ind[2*NUM_FEATURES + 3])\n",
    "gb_lr = max(0.01, best_ind[2*NUM_FEATURES + 4])\n",
    "\n",
    "models = [\n",
    "    HistGradientBoostingRegressor(max_depth=histgb_depth, learning_rate=histgb_lr, max_iter=200, random_state=42),\n",
    "    GradientBoostingRegressor(max_depth=gb_depth, learning_rate=gb_lr, n_estimators=200, random_state=42),\n",
    "]\n",
    "\n",
    "model = models[best_ind[-1]]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "def mostrar_metricas(y_true, y_pred, dataset=\"\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{dataset} | R²: {r2:.4f} | MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f}\")\n",
    "\n",
    "mostrar_metricas(y_train, y_pred_train, \"Entrenamiento\")\n",
    "mostrar_metricas(y_test, y_pred_test, \"Prueba\")\n",
    "print(\"Escalado aplicado:\", bool(best_ind[2*NUM_FEATURES]))\n"
   ],
   "id": "3801fd33ef02c029",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generación 1 ===\n",
      "MSE del mejor individuo: 3.6827\n",
      "Transformaciones seleccionadas por característica:\n",
      "Cta. semillas((1)) -> x^2\n",
      "Singulación(%) -> x^2\n",
      "Dobles(%) -> sin cambio\n",
      "Separación adecuada(%) -> z-score individual\n",
      "Pob. plantas(ksds/ha) -> min-max (0–1)\n",
      "Vacío(inH2O) -> 1/(x+1)\n",
      "Prop. meta(ksds/ha) -> sqrt(x)\n",
      "Humedad(%) -> 1/(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> min-max (0–1)\n",
      "Ca_Mg -> 1/(x+1)\n",
      "Clay -> sqrt(x)\n",
      "Leak -> min-max (0–1)\n",
      "OM -> sin cambio\n",
      "P -> sin cambio\n",
      "Sand -> z-score individual\n",
      "Zn -> sin cambio\n",
      "ndvi -> sqrt(x)\n",
      "NDMI -> z-score individual\n",
      "SAVI -> log(x+1)\n",
      "Cal sing_Bueno -> log(x+1)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.3409015973315154\n",
      "\n",
      "=== Generación 2 ===\n",
      "MSE del mejor individuo: 3.4931\n",
      "Transformaciones seleccionadas por característica:\n",
      "Cta. semillas((1)) -> min-max (0–1)\n",
      "Singulación(%) -> sin cambio\n",
      "Dobles(%) -> log(x+1)\n",
      "Separación adecuada(%) -> min-max (0–1)\n",
      "Pob. plantas(ksds/ha) -> 1/(x+1)\n",
      "Vacío(inH2O) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "B -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> x^2\n",
      "Clay -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "Fe -> log(x+1)\n",
      "Leak -> 1/(x+1)\n",
      "Na -> log(x+1)\n",
      "OM -> 1/(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> log(x+1)\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "NDMI -> min-max (0–1)\n",
      "SAVI -> min-max (0–1)\n",
      "Cal sing_Bueno -> z-score individual\n",
      "Cal sing_Doble -> x^2\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 7, learning_rate: 0.16767547103315467\n",
      "\n",
      "=== Generación 3 ===\n",
      "MSE del mejor individuo: 3.1075\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> sqrt(x)\n",
      "Dobles(%) -> sin cambio\n",
      "Pob. plantas(ksds/ha) -> min-max (0–1)\n",
      "Prop. meta(ksds/ha) -> sqrt(x)\n",
      "Cant. prod. -> x^2\n",
      "% densidad(%) -> 1/(x+1)\n",
      "Humedad(%) -> 1/(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> sqrt(x)\n",
      "Clay -> sin cambio\n",
      "Leak -> sin cambio\n",
      "OM -> 1/(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "ndvi -> min-max (0–1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 4 ===\n",
      "MSE del mejor individuo: 3.1488\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> 1/(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> 1/(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> 1/(x+1)\n",
      "Humedad(%) -> 1/(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> sqrt(x)\n",
      "Clay -> sin cambio\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "OM -> 1/(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 5 ===\n",
      "MSE del mejor individuo: 3.1488\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> 1/(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> 1/(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> 1/(x+1)\n",
      "Humedad(%) -> 1/(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> sqrt(x)\n",
      "Clay -> sin cambio\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "OM -> 1/(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 6 ===\n",
      "MSE del mejor individuo: 3.1488\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> 1/(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> 1/(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> 1/(x+1)\n",
      "Humedad(%) -> 1/(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> sqrt(x)\n",
      "Clay -> sin cambio\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "OM -> 1/(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 7 ===\n",
      "MSE del mejor individuo: 3.1170\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> 1/(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> 1/(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> x^2\n",
      "Clay -> sqrt(x)\n",
      "Leak -> 1/(x+1)\n",
      "Na -> x^2\n",
      "OM -> 1/(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 8 ===\n",
      "MSE del mejor individuo: 3.1032\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Vacío(inH2O) -> sin cambio\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "B -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "K -> log(x+1)\n",
      "Leak -> log(x+1)\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> log(x+1)\n",
      "Silt -> log(x+1)\n",
      "Zn -> min-max (0–1)\n",
      "GNDVI -> sqrt(x)\n",
      "NDMI -> min-max (0–1)\n",
      "SAVI -> min-max (0–1)\n",
      "Cal sing_Bueno -> z-score individual\n",
      "Cal sing_Doble -> x^2\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 9 ===\n",
      "MSE del mejor individuo: 3.0039\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "B -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "K -> log(x+1)\n",
      "Leak -> log(x+1)\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 10 ===\n",
      "MSE del mejor individuo: 3.0039\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "B -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "K -> log(x+1)\n",
      "Leak -> log(x+1)\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:53: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:53: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:53: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\cryxz\\Documents\\UG\\S6\\RedesNeuronalesArtificiales\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:570: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generación 11 ===\n",
      "MSE del mejor individuo: 3.0039\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "B -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "K -> log(x+1)\n",
      "Leak -> log(x+1)\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 12 ===\n",
      "MSE del mejor individuo: 3.0662\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> 1/(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 13 ===\n",
      "MSE del mejor individuo: 3.0229\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> sqrt(x)\n",
      "Saltos(%) -> sqrt(x)\n",
      "Dobles(%) -> sin cambio\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> sin cambio\n",
      "Cant. prod. -> x^2\n",
      "Humedad(%) -> log(x+1)\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> min-max (0–1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> log(x+1)\n",
      "OM -> 1/(x+1)\n",
      "P -> log(x+1)\n",
      "Sand -> sin cambio\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> min-max (0–1)\n",
      "Cal sing_Bueno -> Unknown\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 14 ===\n",
      "MSE del mejor individuo: 2.9731\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Dobles(%) -> sqrt(x)\n",
      "Separación adecuada(%) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> sin cambio\n",
      "Ca -> log(x+1)\n",
      "K -> sin cambio\n",
      "Na -> log(x+1)\n",
      "PAWater -> sin cambio\n",
      "Sand -> log(x+1)\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> 1/(x+1)\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Salto -> z-score individual\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 15 ===\n",
      "MSE del mejor individuo: 2.9699\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Dobles(%) -> log(x+1)\n",
      "Separación adecuada(%) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "Humedad(%) -> sqrt(x)\n",
      "Temp. grano(°C) -> sin cambio\n",
      "Ca -> z-score individual\n",
      "K -> sqrt(x)\n",
      "Na -> x^2\n",
      "PAWater -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 16 ===\n",
      "MSE del mejor individuo: 3.0027\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> sqrt(x)\n",
      "Saltos(%) -> sqrt(x)\n",
      "Dobles(%) -> 1/(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> 1/(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "P -> 1/(x+1)\n",
      "S -> sqrt(x)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDRE -> sin cambio\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 17 ===\n",
      "MSE del mejor individuo: 3.0027\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> sqrt(x)\n",
      "Saltos(%) -> sqrt(x)\n",
      "Dobles(%) -> 1/(x+1)\n",
      "Pob. plantas(ksds/ha) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> 1/(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "P -> 1/(x+1)\n",
      "S -> sqrt(x)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDRE -> sin cambio\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 18 ===\n",
      "MSE del mejor individuo: 3.0220\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Dobles(%) -> log(x+1)\n",
      "Separación adecuada(%) -> sin cambio\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> x^2\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Cu -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> log(x+1)\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> 1/(x+1)\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 19 ===\n",
      "MSE del mejor individuo: 3.0163\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> log(x+1)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> sin cambio\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 20 ===\n",
      "MSE del mejor individuo: 3.0151\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Pob. plantas(ksds/ha) -> sqrt(x)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> x^2\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "Ca -> sqrt(x)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> 1/(x+1)\n",
      "Sand -> z-score individual\n",
      "Silt -> z-score individual\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> sin cambio\n",
      "Rate Qual_Bien -> x^2\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 21 ===\n",
      "MSE del mejor individuo: 3.0163\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> log(x+1)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> sin cambio\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 22 ===\n",
      "MSE del mejor individuo: 3.0163\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> log(x+1)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> sin cambio\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 23 ===\n",
      "MSE del mejor individuo: 3.0157\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> x^2\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 24 ===\n",
      "MSE del mejor individuo: 3.0029\n",
      "Transformaciones seleccionadas por característica:\n",
      "Cta. semillas((1)) -> min-max (0–1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> x^2\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> log(x+1)\n",
      "B -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> sin cambio\n",
      "Leak -> z-score individual\n",
      "Na -> log(x+1)\n",
      "P -> sin cambio\n",
      "Sand -> log(x+1)\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> log(x+1)\n",
      "NDMI -> sin cambio\n",
      "SAVI -> log(x+1)\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> Unknown\n",
      "Rate Qual_Bien -> sin cambio\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 25 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 26 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 27 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> log(x+1)\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 28 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 29 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "=== Generación 30 ===\n",
      "MSE del mejor individuo: 3.0161\n",
      "Transformaciones seleccionadas por característica:\n",
      "Flujo de semilla(ksds/s) -> log(x+1)\n",
      "Saltos(%) -> x^2\n",
      "Dobles(%) -> sqrt(x)\n",
      "Pob. plantas(ksds/ha) -> log(x+1)\n",
      "Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "Cant. prod. -> sqrt(x)\n",
      "% densidad(%) -> log(x+1)\n",
      "Humedad(%) -> sin cambio\n",
      "Temp. grano(°C) -> min-max (0–1)\n",
      "Ca -> log(x+1)\n",
      "Ca_Mg -> log(x+1)\n",
      "Clay -> log(x+1)\n",
      "K -> z-score individual\n",
      "Leak -> sin cambio\n",
      "Na -> x^2\n",
      "P -> sin cambio\n",
      "Sand -> x^2\n",
      "Silt -> log(x+1)\n",
      "Zn -> log(x+1)\n",
      "GNDVI -> x^2\n",
      "NDMI -> sin cambio\n",
      "SAVI -> z-score individual\n",
      "Cal sing_Bueno -> Unknown\n",
      "Cal sing_Doble -> sqrt(x)\n",
      "Rate Qual_Bajo Objetivo -> log(x+1)\n",
      "Rate Qual_Bien -> sqrt(x)\n",
      "\n",
      "Hiperparámetros encontrados:\n",
      "\n",
      "Modelo seleccionado: GradientBoostingRegressor\n",
      "max_depth: 8, learning_rate: 0.13712329969970505\n",
      "\n",
      "Tiempo total AG: 15188.17s\n",
      "\n",
      "=== MEJOR INDIVIDUO ===\n",
      "Modelo: GB\n",
      "Features seleccionadas y transformaciones:\n",
      "  Flujo de semilla(ksds/s) -> log(x+1)\n",
      "  Saltos(%) -> x^2\n",
      "  Dobles(%) -> sqrt(x)\n",
      "  Pob. plantas(ksds/ha) -> log(x+1)\n",
      "  Prop. meta(ksds/ha) -> 1/(x+1)\n",
      "  Cant. prod. -> sqrt(x)\n",
      "  % densidad(%) -> log(x+1)\n",
      "  Humedad(%) -> sin cambio\n",
      "  Temp. grano(°C) -> min-max (0–1)\n",
      "  Ca -> log(x+1)\n",
      "  Ca_Mg -> log(x+1)\n",
      "  Clay -> log(x+1)\n",
      "  K -> z-score individual\n",
      "  Leak -> sin cambio\n",
      "  Na -> x^2\n",
      "  P -> sin cambio\n",
      "  Sand -> x^2\n",
      "  Silt -> log(x+1)\n",
      "  Zn -> log(x+1)\n",
      "  GNDVI -> x^2\n",
      "  NDMI -> sin cambio\n",
      "  SAVI -> z-score individual\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0.0602923043643423",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 214\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFeatures seleccionadas y transformaciones:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    213\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(selected_features_idx):\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_names[idx]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m -> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mtrans_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mselected_transforms\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    216\u001B[39m \u001B[38;5;66;03m# Preparar datos\u001B[39;00m\n\u001B[32m    217\u001B[39m X_sel = X.iloc[:, selected_features_idx]\n",
      "\u001B[31mKeyError\u001B[39m: 0.0602923043643423"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T21:06:01.519931Z",
     "start_time": "2025-10-12T21:05:47.840052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================\n",
    "# CARGA DE DATOS\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "if 'parcela' in df.columns:\n",
    "    df = df.drop(columns=['parcela'])\n",
    "\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# Asegúrate de que las columnas estén en este mismo orden\n",
    "columns = [\n",
    "    \"Flujo de semilla(ksds/s)\", \"Saltos(%)\", \"Dobles(%)\", \"Pob. plantas(ksds/ha)\",\n",
    "    \"Prop. meta(ksds/ha)\", \"Cant. prod.\", \"% densidad(%)\", \"Humedad(%)\",\n",
    "    \"Temp. grano(°C)\", \"Ca\", \"Ca_Mg\", \"Clay\", \"K\", \"Leak\", \"Na\", \"P\", \"Sand\",\n",
    "    \"Silt\", \"Zn\", \"GNDVI\", \"NDMI\", \"SAVI\", \"Cal sing_Bueno\", \"Cal sing_Doble\",\n",
    "    \"Rate Qual_Bajo Objetivo\", \"Rate Qual_Bien\"\n",
    "]\n",
    "\n",
    "target_col = '(seco)Masa de rend.(tonne/ha)'  # Cambia esto si tu variable objetivo tiene otro nombre\n",
    "\n",
    "# ===============================\n",
    "# TRANSFORMACIONES SEGÚN LA GENERACIÓN 30\n",
    "# ===============================\n",
    "df_trans = pd.DataFrame()\n",
    "\n",
    "for col in columns:\n",
    "    if col == \"Flujo de semilla(ksds/s)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Saltos(%)\":\n",
    "        df_trans[col] = df[col] ** 2\n",
    "    elif col == \"Dobles(%)\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"Pob. plantas(ksds/ha)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Prop. meta(ksds/ha)\":\n",
    "        df_trans[col] = 1 / (df[col] + 1)\n",
    "    elif col == \"Cant. prod.\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"% densidad(%)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Humedad(%)\":\n",
    "        df_trans[col] = df[col]\n",
    "    elif col == \"Temp. grano(°C)\":\n",
    "        scaler = MinMaxScaler()\n",
    "        df_trans[col] = scaler.fit_transform(df[[col]])\n",
    "    elif col in [\"Ca\", \"Ca_Mg\", \"Clay\", \"Zn\", \"Silt\"]:\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"K\" or col == \"SAVI\":\n",
    "        df_trans[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    elif col == \"Leak\" or col == \"NDMI\" or col == \"P\":\n",
    "        df_trans[col] = df[col]\n",
    "    elif col == \"Na\" or col == \"Sand\" or col == \"GNDVI\":\n",
    "        df_trans[col] = df[col] ** 2\n",
    "    elif col == \"Cal sing_Bueno\":\n",
    "        df_trans[col] = df[col]  # Unknown -> sin cambio\n",
    "    elif col == \"Cal sing_Doble\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"Rate Qual_Bajo Objetivo\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Rate Qual_Bien\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    else:\n",
    "        df_trans[col] = df[col]\n",
    "\n",
    "# ===============================\n",
    "# SEPARACIÓN DE DATOS\n",
    "# ===============================\n",
    "X = df_trans.values\n",
    "y = df[target_col].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# MODELO OBTENIDO DEL GENÉTICO\n",
    "# ===============================\n",
    "model = HistGradientBoostingRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.13712329969970505,\n",
    "    max_iter=800,  # valor razonable por defecto\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# EVALUACIÓN\n",
    "# ===============================\n",
    "# Predicciones en entrenamiento\n",
    "y_train_pred = model.predict(X_train)\n",
    "# Predicciones en prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Resultados del modelo:\")\n",
    "print(\" - Conjunto de entrenamiento:\")\n",
    "print(f\"    MSE: {mse_train:.4f}, RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}\")\n",
    "print(\" - Conjunto de prueba:\")\n",
    "print(f\"    MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CURVA DE APRENDIZAJE\n",
    "# ===============================\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Cambiar signo para obtener MSE positivo\n",
    "train_scores = -train_scores\n",
    "test_scores = -test_scores\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_sizes, train_mean, label='Entrenamiento', marker='o')\n",
    "plt.plot(train_sizes, test_mean, label='Validación', marker='s')\n",
    "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_mean-test_std, test_mean+test_std, alpha=0.1)\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Curva de aprendizaje - GradientBoostingRegressor (Gen 30)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# MSE: 2.6159, RMSE: 1.6174, MAE: 1.2413, R²: 0.8558"
   ],
   "id": "a088dc1c43613c1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo:\n",
      " - Conjunto de entrenamiento:\n",
      "    MSE: 2.5876, RMSE: 1.6086, MAE: 1.2284, R²: 0.8574\n",
      " - Conjunto de prueba:\n",
      "    MSE: 4.1533, RMSE: 2.0380, MAE: 1.5668, R²: 0.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T00:45:37.060445Z",
     "start_time": "2025-10-13T00:25:21.465835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ===============================\n",
    "# ELIMINAR CLASES EXISTENTES\n",
    "# ===============================\n",
    "if \"FitnessMin\" in creator.__dict__:\n",
    "    del creator.FitnessMin\n",
    "if \"Individual\" in creator.__dict__:\n",
    "    del creator.Individual\n",
    "\n",
    "# ===============================\n",
    "# CARGA DE DATOS\n",
    "# ===============================\n",
    "df = pd.read_csv('Par.csv')\n",
    "if 'parcela' in df.columns:\n",
    "    df = df.drop(columns=['parcela'])\n",
    "\n",
    "cat_cols = ['Cal sing', 'Rate Qual']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# Asegúrate de que las columnas estén en este mismo orden\n",
    "columns = [\n",
    "    \"Flujo de semilla(ksds/s)\", \"Saltos(%)\", \"Dobles(%)\", \"Pob. plantas(ksds/ha)\",\n",
    "    \"Prop. meta(ksds/ha)\", \"Cant. prod.\", \"% densidad(%)\", \"Humedad(%)\",\n",
    "    \"Temp. grano(°C)\", \"Ca\", \"Ca_Mg\", \"Clay\", \"K\", \"Leak\", \"Na\", \"P\", \"Sand\",\n",
    "    \"Silt\", \"Zn\", \"GNDVI\", \"NDMI\", \"SAVI\", \"Cal sing_Bueno\", \"Cal sing_Doble\",\n",
    "    \"Rate Qual_Bajo Objetivo\", \"Rate Qual_Bien\"\n",
    "]\n",
    "\n",
    "target_col = '(seco)Masa de rend.(tonne/ha)'  # Cambia esto si tu variable objetivo tiene otro nombre\n",
    "\n",
    "# ===============================\n",
    "# TRANSFORMACIONES SEGÚN LA GENERACIÓN 30\n",
    "# ===============================\n",
    "df_trans = pd.DataFrame()\n",
    "\n",
    "for col in columns:\n",
    "    if col == \"Flujo de semilla(ksds/s)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Saltos(%)\":\n",
    "        df_trans[col] = df[col] ** 2\n",
    "    elif col == \"Dobles(%)\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"Pob. plantas(ksds/ha)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Prop. meta(ksds/ha)\":\n",
    "        df_trans[col] = 1 / (df[col] + 1)\n",
    "    elif col == \"Cant. prod.\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"% densidad(%)\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Humedad(%)\":\n",
    "        df_trans[col] = df[col]\n",
    "    elif col == \"Temp. grano(°C)\":\n",
    "        scaler = MinMaxScaler()\n",
    "        df_trans[col] = scaler.fit_transform(df[[col]])\n",
    "    elif col in [\"Ca\", \"Ca_Mg\", \"Clay\", \"Zn\", \"Silt\"]:\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"K\" or col == \"SAVI\":\n",
    "        df_trans[col] = StandardScaler().fit_transform(df[[col]])\n",
    "    elif col == \"Leak\" or col == \"NDMI\" or col == \"P\":\n",
    "        df_trans[col] = df[col]\n",
    "    elif col == \"Na\" or col == \"Sand\" or col == \"GNDVI\":\n",
    "        df_trans[col] = df[col] ** 2\n",
    "    elif col == \"Cal sing_Bueno\":\n",
    "        df_trans[col] = df[col]  # Unknown -> sin cambio\n",
    "    elif col == \"Cal sing_Doble\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    elif col == \"Rate Qual_Bajo Objetivo\":\n",
    "        df_trans[col] = np.log1p(df[col])\n",
    "    elif col == \"Rate Qual_Bien\":\n",
    "        df_trans[col] = np.sqrt(df[col])\n",
    "    else:\n",
    "        df_trans[col] = df[col]\n",
    "\n",
    "# ===============================\n",
    "# SEPARAR DATOS (ya transformados)\n",
    "# ===============================\n",
    "X = df_trans.values\n",
    "y = df[target_col].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURACIÓN DE DEAP - MODIFICADO PARA AG SIMPLE\n",
    "# ===============================\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # AHORA: función compuesta única\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Rangos de hiperparámetros (solo lr y max_iter, max_depth fijo en 3)\n",
    "toolbox.register(\"attr_max_iter\", random.randint, 100, 1000)\n",
    "toolbox.register(\"attr_lr\", random.uniform, 0.01, 0.5)\n",
    "\n",
    "# Crear individuos y población (solo 2 parámetros)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_max_iter, toolbox.attr_lr), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# ===============================\n",
    "# FUNCIÓN DE EVALUACIÓN COMPUESTA - MODIFICADA\n",
    "# ===============================\n",
    "def eval_compuesta(individual):\n",
    "    max_iter, lr = individual\n",
    "    max_depth = 3  # FIJO en 3 como solicitaste\n",
    "\n",
    "    # Asegurar que los parámetros estén en los rangos correctos\n",
    "    max_iter = int(round(max(100, min(1000, max_iter))))\n",
    "    lr = max(0.01, min(0.5, lr))\n",
    "\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_depth=max_depth,\n",
    "        max_iter=max_iter,\n",
    "        learning_rate=lr,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Métricas\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # FUNCIÓN COMPUESTA: Combinamos MSE test y R² test\n",
    "    # Penalizamos si la diferencia entre train y test es muy grande\n",
    "    diff_penalty = abs(mse_train - mse_test) * 0.1\n",
    "    r2_penalty = (1 - r2_test) * 0.5  # Penalización por bajo R²\n",
    "\n",
    "    # Función compuesta final (queremos minimizar esto)\n",
    "    compuesta = mse_test + diff_penalty + r2_penalty\n",
    "\n",
    "    return (compuesta,)\n",
    "\n",
    "toolbox.register(\"evaluate\", eval_compuesta)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "\n",
    "# ===============================\n",
    "# MUTACIÓN SEGURA\n",
    "# ===============================\n",
    "def mutate_safe(individual, indpb=0.2):\n",
    "    # max_iter\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = individual[0] + random.randint(-50, 50)\n",
    "    individual[0] = max(100, min(1000, individual[0]))\n",
    "\n",
    "    # learning_rate\n",
    "    if random.random() < indpb:\n",
    "        individual[1] = individual[1] + random.uniform(-0.05, 0.05)\n",
    "    individual[1] = max(0.01, min(0.5, individual[1]))\n",
    "\n",
    "    return individual,\n",
    "\n",
    "toolbox.register(\"mutate\", mutate_safe, indpb=0.3)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # SELECCIÓN SIMPLE\n",
    "\n",
    "# ===============================\n",
    "# FUNCIÓN PARA REPARAR INDIVIDUOS\n",
    "# ===============================\n",
    "def check_bounds(individual):\n",
    "    individual[0] = max(100, min(1000, individual[0]))\n",
    "    individual[1] = max(0.01, min(0.5, individual[1]))\n",
    "    return individual\n",
    "\n",
    "# ===============================\n",
    "# EJECUCIÓN DEL AG SIMPLE\n",
    "# ===============================\n",
    "population = toolbox.population(n=50)  # Población más grande para AG simple\n",
    "\n",
    "# Evaluar población inicial\n",
    "invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "fits = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "for fit, ind in zip(fits, invalid_ind):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "NGEN = 30  # Menas generaciones para AG simple\n",
    "CXPB = 0.7  # Mayor probabilidad de cruza\n",
    "MUTPB = 0.2  # Menor probabilidad de mutación\n",
    "\n",
    "print(\"Iniciando algoritmo genético simple...\")\n",
    "print(\"Optimizando: max_iter [100-1000], lr [0.01-0.5], max_depth=3 (fijo)\")\n",
    "\n",
    "for gen in range(NGEN):\n",
    "    # Selección\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "\n",
    "    # Clonar\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Cruza\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    # Mutación\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Reparar y evaluar nuevos individuos\n",
    "    for ind in offspring:\n",
    "        ind = check_bounds(ind)\n",
    "        if not ind.fitness.valid:\n",
    "            ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "    # Reemplazar población\n",
    "    population[:] = offspring\n",
    "\n",
    "    # Mejor individuo de la generación\n",
    "    best = tools.selBest(population, 1)[0]\n",
    "\n",
    "    # Entrenar modelo para imprimir métricas completas\n",
    "    model_best = HistGradientBoostingRegressor(\n",
    "        max_depth=3,  # FIJO\n",
    "        max_iter=int(best[0]),\n",
    "        learning_rate=best[1],\n",
    "        random_state=42\n",
    "    )\n",
    "    model_best.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model_best.predict(X_train)\n",
    "    y_test_pred = model_best.predict(X_test)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    compuesta = best.fitness.values[0]\n",
    "\n",
    "    print(f\"\\nGen {gen+1}: Mejor individuo\")\n",
    "    print(f\"max_depth=3, max_iter={int(best[0])}, lr={best[1]:.4f}\")\n",
    "    print(f\"Función compuesta: {compuesta:.4f}\")\n",
    "    print(f\"MSE Train={mse_train:.4f}, RMSE Train={rmse_train:.4f}, MAE Train={mae_train:.4f}, R² Train={r2_train:.4f}\")\n",
    "    print(f\"MSE Test={mse_test:.4f}, RMSE Test={rmse_test:.4f}, MAE Test={mae_test:.4f}, R² Test={r2_test:.4f}\")\n",
    "    print(f\"Diferencia MSE={abs(mse_train-mse_test):.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# MEJOR MODELO FINAL\n",
    "# ===============================\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "final_model = HistGradientBoostingRegressor(\n",
    "    max_depth=3,  # FIJO\n",
    "    max_iter=int(best_ind[0]),\n",
    "    learning_rate=best_ind[1],\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MEJOR MODELO FINAL:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Parámetros optimizados:\")\n",
    "print(f\"max_depth=3 (fijo)\")\n",
    "print(f\"max_iter={int(best_ind[0])}\")\n",
    "print(f\"learning_rate={best_ind[1]:.4f}\")\n",
    "print(f\"\\nMétricas de entrenamiento:\")\n",
    "print(f\"MSE Train={mse_train:.4f}, RMSE Train={rmse_train:.4f}\")\n",
    "print(f\"MAE Train={mae_train:.4f}, R² Train={r2_train:.4f}\")\n",
    "print(f\"\\nMétricas de test:\")\n",
    "print(f\"MSE Test={mse_test:.4f}, RMSE Test={rmse_test:.4f}\")\n",
    "print(f\"MAE Test={mae_test:.4f}, R² Test={r2_test:.4f}\")\n",
    "print(f\"\\nDiferencia MSE Train-Test: {abs(mse_train-mse_test):.4f}\")\n",
    "print(f\"Función compuesta final: {best_ind.fitness.values[0]:.4f}\")"
   ],
   "id": "8635d50a3aa108c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando algoritmo genético simple...\n",
      "Optimizando: max_iter [100-1000], lr [0.01-0.5], max_depth=3 (fijo)\n",
      "\n",
      "Gen 1: Mejor individuo\n",
      "max_depth=3, max_iter=919, lr=0.3177\n",
      "Función compuesta: 4.0863\n",
      "MSE Train=1.3900, RMSE Train=1.1790, MAE Train=0.8934, R² Train=0.9234\n",
      "MSE Test=3.7500, RMSE Test=1.9365, MAE Test=1.4781, R² Test=0.7966\n",
      "Diferencia MSE=2.3600\n",
      "\n",
      "Gen 2: Mejor individuo\n",
      "max_depth=3, max_iter=847, lr=0.2713\n",
      "Función compuesta: 4.0693\n",
      "MSE Train=1.6513, RMSE Train=1.2850, MAE Train=0.9732, R² Train=0.9090\n",
      "MSE Test=3.7591, RMSE Test=1.9388, MAE Test=1.4778, R² Test=0.7961\n",
      "Diferencia MSE=2.1078\n",
      "\n",
      "Gen 3: Mejor individuo\n",
      "max_depth=3, max_iter=975, lr=0.2534\n",
      "Función compuesta: 4.0688\n",
      "MSE Train=1.5745, RMSE Train=1.2548, MAE Train=0.9509, R² Train=0.9132\n",
      "MSE Test=3.7496, RMSE Test=1.9364, MAE Test=1.4741, R² Test=0.7966\n",
      "Diferencia MSE=2.1751\n",
      "\n",
      "Gen 4: Mejor individuo\n",
      "max_depth=3, max_iter=975, lr=0.2534\n",
      "Función compuesta: 4.0688\n",
      "MSE Train=1.5745, RMSE Train=1.2548, MAE Train=0.9509, R² Train=0.9132\n",
      "MSE Test=3.7496, RMSE Test=1.9364, MAE Test=1.4741, R² Test=0.7966\n",
      "Diferencia MSE=2.1751\n",
      "\n",
      "Gen 5: Mejor individuo\n",
      "max_depth=3, max_iter=967, lr=0.3177\n",
      "Función compuesta: 4.0367\n",
      "MSE Train=1.3555, RMSE Train=1.1643, MAE Train=0.8818, R² Train=0.9253\n",
      "MSE Test=3.7017, RMSE Test=1.9240, MAE Test=1.4593, R² Test=0.7992\n",
      "Diferencia MSE=2.3461\n",
      "\n",
      "Gen 6: Mejor individuo\n",
      "max_depth=3, max_iter=892, lr=0.3176\n",
      "Función compuesta: 4.0837\n",
      "MSE Train=1.4330, RMSE Train=1.1971, MAE Train=0.9093, R² Train=0.9210\n",
      "MSE Test=3.7493, RMSE Test=1.9363, MAE Test=1.4732, R² Test=0.7966\n",
      "Diferencia MSE=2.3163\n",
      "\n",
      "Gen 7: Mejor individuo\n",
      "max_depth=3, max_iter=1000, lr=0.3166\n",
      "Función compuesta: 4.0456\n",
      "MSE Train=1.3092, RMSE Train=1.1442, MAE Train=0.8643, R² Train=0.9278\n",
      "MSE Test=3.7055, RMSE Test=1.9250, MAE Test=1.4658, R² Test=0.7990\n",
      "Diferencia MSE=2.3963\n",
      "\n",
      "Gen 8: Mejor individuo\n",
      "max_depth=3, max_iter=1000, lr=0.3197\n",
      "Función compuesta: 4.0641\n",
      "MSE Train=1.2861, RMSE Train=1.1341, MAE Train=0.8577, R² Train=0.9291\n",
      "MSE Test=3.7199, RMSE Test=1.9287, MAE Test=1.4559, R² Test=0.7982\n",
      "Diferencia MSE=2.4338\n",
      "\n",
      "Gen 9: Mejor individuo\n",
      "max_depth=3, max_iter=957, lr=0.3223\n",
      "Función compuesta: 4.0432\n",
      "MSE Train=1.3369, RMSE Train=1.1562, MAE Train=0.8741, R² Train=0.9263\n",
      "MSE Test=3.7060, RMSE Test=1.9251, MAE Test=1.4654, R² Test=0.7990\n",
      "Diferencia MSE=2.3692\n",
      "\n",
      "Gen 10: Mejor individuo\n",
      "max_depth=3, max_iter=1000, lr=0.2970\n",
      "Función compuesta: 3.9899\n",
      "MSE Train=1.3768, RMSE Train=1.1734, MAE Train=0.8883, R² Train=0.9241\n",
      "MSE Test=3.6620, RMSE Test=1.9136, MAE Test=1.4505, R² Test=0.8014\n",
      "Diferencia MSE=2.2852\n",
      "\n",
      "Gen 11: Mejor individuo\n",
      "max_depth=3, max_iter=1000, lr=0.2970\n",
      "Función compuesta: 3.9899\n",
      "MSE Train=1.3768, RMSE Train=1.1734, MAE Train=0.8883, R² Train=0.9241\n",
      "MSE Test=3.6620, RMSE Test=1.9136, MAE Test=1.4505, R² Test=0.8014\n",
      "Diferencia MSE=2.2852\n",
      "\n",
      "Gen 12: Mejor individuo\n",
      "max_depth=3, max_iter=911, lr=0.3178\n",
      "Función compuesta: 4.0308\n",
      "MSE Train=1.4080, RMSE Train=1.1866, MAE Train=0.9000, R² Train=0.9224\n",
      "MSE Test=3.7011, RMSE Test=1.9238, MAE Test=1.4597, R² Test=0.7992\n",
      "Diferencia MSE=2.2932\n",
      "\n",
      "Gen 13: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 14: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 15: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 16: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 17: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 18: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 19: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 20: Mejor individuo\n",
      "max_depth=3, max_iter=997, lr=0.3164\n",
      "Función compuesta: 4.0032\n",
      "MSE Train=1.3238, RMSE Train=1.1506, MAE Train=0.8691, R² Train=0.9270\n",
      "MSE Test=3.6695, RMSE Test=1.9156, MAE Test=1.4638, R² Test=0.8009\n",
      "Diferencia MSE=2.3458\n",
      "\n",
      "Gen 21: Mejor individuo\n",
      "max_depth=3, max_iter=987, lr=0.3164\n",
      "Función compuesta: 4.0007\n",
      "MSE Train=1.3335, RMSE Train=1.1548, MAE Train=0.8726, R² Train=0.9265\n",
      "MSE Test=3.6683, RMSE Test=1.9153, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3348\n",
      "\n",
      "Gen 22: Mejor individuo\n",
      "max_depth=3, max_iter=988, lr=0.3164\n",
      "Función compuesta: 4.0007\n",
      "MSE Train=1.3333, RMSE Train=1.1547, MAE Train=0.8725, R² Train=0.9265\n",
      "MSE Test=3.6679, RMSE Test=1.9152, MAE Test=1.4635, R² Test=0.8010\n",
      "Diferencia MSE=2.3347\n",
      "\n",
      "Gen 23: Mejor individuo\n",
      "max_depth=3, max_iter=984, lr=0.3164\n",
      "Función compuesta: 4.0006\n",
      "MSE Train=1.3365, RMSE Train=1.1561, MAE Train=0.8737, R² Train=0.9263\n",
      "MSE Test=3.6685, RMSE Test=1.9153, MAE Test=1.4646, R² Test=0.8010\n",
      "Diferencia MSE=2.3319\n",
      "\n",
      "Gen 24: Mejor individuo\n",
      "max_depth=3, max_iter=988, lr=0.3164\n",
      "Función compuesta: 4.0010\n",
      "MSE Train=1.3333, RMSE Train=1.1547, MAE Train=0.8725, R² Train=0.9265\n",
      "MSE Test=3.6680, RMSE Test=1.9152, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3347\n",
      "\n",
      "Gen 25: Mejor individuo\n",
      "max_depth=3, max_iter=988, lr=0.3164\n",
      "Función compuesta: 4.0008\n",
      "MSE Train=1.3333, RMSE Train=1.1547, MAE Train=0.8725, R² Train=0.9265\n",
      "MSE Test=3.6680, RMSE Test=1.9152, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3348\n",
      "\n",
      "Gen 26: Mejor individuo\n",
      "max_depth=3, max_iter=987, lr=0.3164\n",
      "Función compuesta: 4.0008\n",
      "MSE Train=1.3335, RMSE Train=1.1548, MAE Train=0.8726, R² Train=0.9265\n",
      "MSE Test=3.6683, RMSE Test=1.9153, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3349\n",
      "\n",
      "Gen 27: Mejor individuo\n",
      "max_depth=3, max_iter=987, lr=0.3164\n",
      "Función compuesta: 4.0008\n",
      "MSE Train=1.3335, RMSE Train=1.1548, MAE Train=0.8726, R² Train=0.9265\n",
      "MSE Test=3.6683, RMSE Test=1.9153, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3349\n",
      "\n",
      "Gen 28: Mejor individuo\n",
      "max_depth=3, max_iter=988, lr=0.3164\n",
      "Función compuesta: 4.0007\n",
      "MSE Train=1.3333, RMSE Train=1.1547, MAE Train=0.8725, R² Train=0.9265\n",
      "MSE Test=3.6679, RMSE Test=1.9152, MAE Test=1.4635, R² Test=0.8010\n",
      "Diferencia MSE=2.3347\n",
      "\n",
      "Gen 29: Mejor individuo\n",
      "max_depth=3, max_iter=988, lr=0.3164\n",
      "Función compuesta: 4.0009\n",
      "MSE Train=1.3333, RMSE Train=1.1547, MAE Train=0.8725, R² Train=0.9265\n",
      "MSE Test=3.6681, RMSE Test=1.9152, MAE Test=1.4637, R² Test=0.8010\n",
      "Diferencia MSE=2.3348\n",
      "\n",
      "Gen 30: Mejor individuo\n",
      "max_depth=3, max_iter=989, lr=0.3164\n",
      "Función compuesta: 4.0009\n",
      "MSE Train=1.3324, RMSE Train=1.1543, MAE Train=0.8723, R² Train=0.9266\n",
      "MSE Test=3.6679, RMSE Test=1.9152, MAE Test=1.4636, R² Test=0.8010\n",
      "Diferencia MSE=2.3355\n",
      "\n",
      "==================================================\n",
      "MEJOR MODELO FINAL:\n",
      "==================================================\n",
      "Parámetros optimizados:\n",
      "max_depth=3 (fijo)\n",
      "max_iter=989\n",
      "learning_rate=0.3164\n",
      "\n",
      "Métricas de entrenamiento:\n",
      "MSE Train=1.3324, RMSE Train=1.1543\n",
      "MAE Train=0.8723, R² Train=0.9266\n",
      "\n",
      "Métricas de test:\n",
      "MSE Test=3.6679, RMSE Test=1.9152\n",
      "MAE Test=1.4636, R² Test=0.8010\n",
      "\n",
      "Diferencia MSE Train-Test: 2.3355\n",
      "Función compuesta final: 4.0009\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
